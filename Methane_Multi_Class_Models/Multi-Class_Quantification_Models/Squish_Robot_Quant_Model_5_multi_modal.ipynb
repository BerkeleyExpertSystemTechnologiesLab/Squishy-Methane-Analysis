{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jbsdoki/Squishy_Robots_Quant_Models/blob/main/Squish_Robot_Quant_Model_5_multi_modal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Description\n",
        "\n",
        "This model was produced by and for Squishy Robotics for the task of identifying and classifying methane leaks.\n",
        "\n",
        "\n",
        "This model was made in conjunction with a synthetic dataset of 2 channel, 240 by 320 greyscale images of methane leaks\n",
        "(2 x 240 x 320)\n",
        "The first channel is a greyscale background image and the second channel is a greyscale gas plume image.\n",
        "\n",
        "\n",
        "\n",
        "This model is experimental and uses the Optuna Hyperparameter Optimizer to search for successful hyperparameters (Learning Rate, Optimizer, Batch Size, Dropout %, etc...) and different optimizers. As such if you want to test a specific Model architecture you need to comment out the Optuna code and run a train/test on that specific model."
      ],
      "metadata": {
        "id": "Rf3vlYMJAK6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna #Hyperparameter Optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGzW9O1lKUhh",
        "outputId": "81b09393-2a90-4d21-da60-5c732edd6268"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.0)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/400.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Hyperparameter Search\n",
        "import optuna\n",
        "\n",
        "import json\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "tzEL-OHlG6G6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "n8JlSIL8-qyE"
      },
      "outputs": [],
      "source": [
        "# This may take several minutes, the synthetic dataset can be large\n",
        "!unzip -q Final_Dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01635a9"
      },
      "source": [
        "## Print out the structure of the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an example file to demonstrate the dimensions\n",
        "# This file might not exist, change the name to one that does to show the\n",
        "# dimensions\n",
        "file_path = './Final_Dataset/data/class_0/1237_frame_1004_class_0.npy'\n",
        "sample_data = np.load(file_path)\n",
        "print(f\"Shape of preprocessed sample data: {sample_data.shape}\")\n",
        "print(f\"Data type of preprocessed sample data: {sample_data.dtype}\")\n",
        "\n",
        "# GasVid synthetic processed dataset should be 2 channels, 240x320 in dimension"
      ],
      "metadata": {
        "id": "6dIk3Tx7GVXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07fd3390-6624-4434-c4bb-e408dd589098"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of preprocessed sample data: (2, 240, 320)\n",
            "Data type of preprocessed sample data: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the data is in 'Final_Dataset/data' and class folders are named 'class_0' ... 'class_7'\n",
        "data_dir = 'Final_Dataset/data'\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "print(f\"Classes: {classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqd6wbUTkgH6",
        "outputId": "fa2da37c-7b06-4d38-f610-a17b81fb3ce1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb4a66a"
      },
      "source": [
        "## Create a dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Multi_Modal_Dataset(Dataset):\n",
        "    def __init__(self, numpy_files, json_files, labels):\n",
        "        \"\"\"\n",
        "        numpy_dir points to all the numpy 2 channel frames that were collected\n",
        "          from METEC. This is designed to be 1st Channel Greyscale image of\n",
        "          background, 2nd channel is just the gas plume scaled to some ppm\n",
        "        json_dir points to all the metadata (ppm, distance, etc) that was\n",
        "          collected from METEC or estimated using BEST Labs algorithms\n",
        "        \"\"\"\n",
        "        self.numpy_files = numpy_files\n",
        "        self.json_files = json_files\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.numpy_files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      numpy_path = self.numpy_files[idx]\n",
        "      image_data = np.load(numpy_path)\n",
        "      image_tensor = torch.from_numpy(image_data).float()\n",
        "\n",
        "      json_path = self.json_files[idx]\n",
        "      with open(json_path, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "      metadat_features = self._extract_metadata_features(metadata)\n",
        "      metadata_tensor = torch.tensor(metadat_features, dtype=torch.float32)\n",
        "\n",
        "      label = self.labels[idx]\n",
        "\n",
        "      return image_tensor, metadata_tensor, label\n",
        "\n",
        "\n",
        "    def _extract_metadata_features(self, metadata):\n",
        "      \"\"\"\n",
        "      Extracts a few entries from the metadata.\n",
        "        For now:\n",
        "          distance\n",
        "          ppm\n",
        "        In the future\n",
        "          windspeed\n",
        "          angle?\n",
        "      \"\"\"\n",
        "\n",
        "      features = []\n",
        "\n",
        "      # If the features exist, extract them, else place 0.0\n",
        "      # Print warning statements if unable to retrieve the data\n",
        "      distance = metadata.get(\"distance_m\", None)\n",
        "      if distance is None or distance == 0.0:\n",
        "          print(f\"WARNING: Invalid or missing distance_m value: {distance}\")\n",
        "          print(f\"  Metadata keys available: {list(metadata.keys())}\")\n",
        "          features.append(0.0)\n",
        "      else:\n",
        "          features.append(distance)\n",
        "\n",
        "      ppm = metadata.get(\"ppm\", None)\n",
        "      if ppm is None:\n",
        "          print(f\"WARNING: Missing ppm value\")\n",
        "          print(f\"  Metadata keys available: {list(metadata.keys())}\")\n",
        "          features.append(0.0)\n",
        "      else:\n",
        "          features.append(ppm)\n",
        "\n",
        "      return features"
      ],
      "metadata": {
        "id": "5JMbhRnSjMGa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_dir = \"./Final_Dataset/data\"\n",
        "json_dir = \"./Final_Dataset/metadata\"\n",
        "\n",
        "all_numpy_files = []\n",
        "all_json_files = []\n",
        "all_labels = []\n",
        "\n",
        "print(f\"Looking in: {numpy_dir}\")\n",
        "print(f\"Directory exists: {os.path.exists(numpy_dir)}\\n\")\n",
        "\n",
        "# Load each class separatley, collect the numpy and json files for a certain\n",
        "# class at the same time\n",
        "for class_idx in range(8):\n",
        "    numpy_class_dir = os.path.join(numpy_dir, f\"class_{class_idx}\")\n",
        "    json_class_dir = os.path.join(json_dir, f\"class_{class_idx}\")\n",
        "\n",
        "    numpy_files_in_class = sorted(glob.glob(os.path.join(numpy_class_dir, \"*.npy\")))\n",
        "\n",
        "    print(f\"Class {class_idx}: Found {len(numpy_files_in_class)} files\")\n",
        "\n",
        "    for numpy_file in numpy_files_in_class:\n",
        "        base_name = os.path.splitext(os.path.basename(numpy_file))[0]\n",
        "        video_id = base_name.split('_')[0]\n",
        "\n",
        "\n",
        "        json_filename = f\"{video_id}_class_{class_idx}.json\"\n",
        "        json_file = os.path.join(json_class_dir, json_filename)\n",
        "\n",
        "        if os.path.exists(json_file):\n",
        "            all_numpy_files.append(numpy_file)\n",
        "            all_json_files.append(json_file)\n",
        "            all_labels.append(class_idx)\n",
        "        else:\n",
        "            print(f\"WARNING: JSON missing for {base_name}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"TOTAL: {len(all_numpy_files)} numpy files\")\n",
        "print(f\"TOTAL: {len(all_json_files)} json files\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Only continue if we have files\n",
        "if len(all_numpy_files) == 0:\n",
        "    raise ValueError(\"No files found! Check your paths above.\")\n",
        "\n",
        "# Now continue with video splitting\n",
        "video_to_indices = defaultdict(list)\n",
        "for idx, numpy_file in enumerate(all_numpy_files):\n",
        "    video_id = os.path.basename(numpy_file).split('_')[0]\n",
        "    video_to_indices[video_id].append(idx)\n",
        "\n",
        "print(f\"Number of unique videos: {len(video_to_indices)}\")\n",
        "print(f\"Video IDs: {sorted(video_to_indices.keys())}\\n\")\n",
        "\n",
        "# ... rest of your code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5__gzKDL2yqk",
        "outputId": "10132875-47b0-4abb-da03-d1da572ee2d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in: ./Final_Dataset/data\n",
            "Directory exists: True\n",
            "\n",
            "Class 0: Found 5395 files\n",
            "Class 1: Found 5393 files\n",
            "Class 2: Found 5393 files\n",
            "Class 3: Found 5397 files\n",
            "Class 4: Found 5382 files\n",
            "Class 5: Found 5411 files\n",
            "Class 6: Found 5380 files\n",
            "Class 7: Found 5406 files\n",
            "\n",
            "============================================================\n",
            "TOTAL: 43157 numpy files\n",
            "TOTAL: 43157 json files\n",
            "============================================================\n",
            "\n",
            "Number of unique videos: 28\n",
            "Video IDs: ['1237', '1238', '1239', '1240', '1241', '1242', '1467', '1468', '1469', '1470', '1471', '1472', '2559', '2560', '2561', '2562', '2563', '2564', '2566', '2567', '2568', '2569', '2571', '2578', '2579', '2580', '2581', '2583']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_to_indices = defaultdict(list) #Make an empty dictionary of lists\n",
        "\n",
        "for idx, numpy_file in enumerate(all_numpy_files):\n",
        "    video_id = os.path.basename(numpy_file).split('_')[0] #Extract 4 digit code from numpy filename\n",
        "    video_to_indices[video_id].append(idx)\n",
        "\n",
        "video_ids = list(video_to_indices.keys())\n",
        "\n",
        "# Split the video into train and test\n",
        "train_vids, test_vids = train_test_split(video_ids, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verify no overlap\n",
        "overlap = set(train_vids) & set(test_vids)\n",
        "if overlap:\n",
        "    print(f\"\\nVideos overlap: {overlap}\")\n",
        "else:\n",
        "    print(f\"\\nNo video overlap - train and test are separate\")\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "for vid in train_vids:\n",
        "    train_indices.extend(video_to_indices[vid])\n",
        "for vid in test_vids:\n",
        "    test_indices.extend(video_to_indices[vid])\n",
        "\n",
        "# Create file lists\n",
        "train_numpy = [all_numpy_files[i] for i in train_indices]\n",
        "train_json = [all_json_files[i] for i in train_indices]\n",
        "train_labels_list = [all_labels[i] for i in train_indices]\n",
        "\n",
        "test_numpy = [all_numpy_files[i] for i in test_indices]\n",
        "test_json = [all_json_files[i] for i in test_indices]\n",
        "test_labels_list = [all_labels[i] for i in test_indices]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNK0bdp8o9hM",
        "outputId": "3ee50e6b-c933-44b9-a573-22b11e78c873"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video ID's:  ['1237', '1238', '1239', '1240', '1241', '1242', '1467', '1468', '1469', '1470', '1471', '1472', '2559', '2560', '2561', '2562', '2563', '2564', '2566', '2567', '2568', '2569', '2571', '2578', '2579', '2580', '2581', '2583']\n",
            "\n",
            "No video overlap - train and test are separate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW FINAL SPLIT STATISTICS\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DATASET STATISTICS\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\nTRAINING SET:\")\n",
        "print(f\"   Total samples: {len(train_numpy)}\")\n",
        "print(f\"   From {len(train_vids)} videos: {sorted(train_vids)}\")\n",
        "\n",
        "# Count samples per class in training\n",
        "train_class_counts = Counter(train_labels_list)\n",
        "print(f\"\\n   Samples per class:\")\n",
        "for class_id in range(8):\n",
        "    count = train_class_counts.get(class_id, 0)\n",
        "    percentage = (count / len(train_numpy) * 100) if len(train_numpy) > 0 else 0\n",
        "    print(f\"      Class {class_id}: {count:5d} samples ({percentage:5.2f}%)\")\n",
        "\n",
        "print(f\"\\nTEST SET:\")\n",
        "print(f\"   Total samples: {len(test_numpy)}\")\n",
        "print(f\"   From {len(test_vids)} videos: {sorted(test_vids)}\")\n",
        "\n",
        "# Count samples per class in testing\n",
        "test_class_counts = Counter(test_labels_list)\n",
        "print(f\"\\n   Samples per class:\")\n",
        "for class_id in range(8):\n",
        "    count = test_class_counts.get(class_id, 0)\n",
        "    percentage = (count / len(test_numpy) * 100) if len(test_numpy) > 0 else 0\n",
        "    print(f\"      Class {class_id}: {count:5d} samples ({percentage:5.2f}%)\")\n",
        "\n",
        "# VERIFY ALL CLASSES PRESENT\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train_classes = set(train_labels_list)\n",
        "test_classes = set(test_labels_list)\n",
        "missing_train = set(range(8)) - train_classes\n",
        "missing_test = set(range(8)) - test_classes\n",
        "\n",
        "if missing_train:\n",
        "    print(f\"WARNING: Training missing classes {missing_train}\")\n",
        "else:\n",
        "    print(f\"Training set has all 8 classes\")\n",
        "\n",
        "if missing_test:\n",
        "    print(f\"WARNING: Testing missing classes {missing_test}\")\n",
        "else:\n",
        "    print(f\"Test set has all 8 classes\")\n",
        "\n",
        "# Show train/test split ratio\n",
        "total_samples = len(train_numpy) + len(test_numpy)\n",
        "train_ratio = len(train_numpy) / total_samples * 100\n",
        "test_ratio = len(test_numpy) / total_samples * 100\n",
        "print(f\"\\nSplit ratio: {train_ratio:.1f}% train / {test_ratio:.1f}% test\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DATA SPLIT COMPLETE AND VERIFIED\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnsZFZCrETks",
        "outputId": "20396474-3a78-4135-9076-632f54be989b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET STATISTICS\n",
            "==========================================================================================\n",
            "\n",
            "TRAINING SET:\n",
            "   Total samples: 33903\n",
            "   From 22 videos: ['1238', '1239', '1240', '1241', '1242', '1467', '1468', '1471', '1472', '2560', '2561', '2562', '2563', '2564', '2566', '2567', '2568', '2571', '2578', '2579', '2581', '2583']\n",
            "\n",
            "   Samples per class:\n",
            "      Class 0:  4232 samples (12.48%)\n",
            "      Class 1:  4232 samples (12.48%)\n",
            "      Class 2:  4242 samples (12.51%)\n",
            "      Class 3:  4243 samples (12.52%)\n",
            "      Class 4:  4232 samples (12.48%)\n",
            "      Class 5:  4250 samples (12.54%)\n",
            "      Class 6:  4229 samples (12.47%)\n",
            "      Class 7:  4243 samples (12.52%)\n",
            "\n",
            "TEST SET:\n",
            "   Total samples: 9254\n",
            "   From 6 videos: ['1237', '1469', '1470', '2559', '2569', '2580']\n",
            "\n",
            "   Samples per class:\n",
            "      Class 0:  1163 samples (12.57%)\n",
            "      Class 1:  1161 samples (12.55%)\n",
            "      Class 2:  1151 samples (12.44%)\n",
            "      Class 3:  1154 samples (12.47%)\n",
            "      Class 4:  1150 samples (12.43%)\n",
            "      Class 5:  1161 samples (12.55%)\n",
            "      Class 6:  1151 samples (12.44%)\n",
            "      Class 7:  1163 samples (12.57%)\n",
            "\n",
            "======================================================================\n",
            "VERIFICATION\n",
            "======================================================================\n",
            "Training set has all 8 classes\n",
            "Test set has all 8 classes\n",
            "\n",
            "Split ratio: 78.6% train / 21.4% test\n",
            "\n",
            "======================================================================\n",
            "DATA SPLIT COMPLETE AND VERIFIED\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Multi_Modal_Dataset(train_numpy, train_json, train_labels_list)\n",
        "test_dataset = Multi_Modal_Dataset(test_numpy, test_json, test_labels_list)"
      ],
      "metadata": {
        "id": "z8GY3A5zprqh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812eecda"
      },
      "source": [
        "# Define the CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5afeb9da"
      },
      "source": [
        "## Define the Optuna Objective Function\n",
        "\n",
        "This function will be called by Optuna for each trial. It will:\n",
        "1. Suggest hyperparameters using the trial object.\n",
        "2. Build and train the CNN model with the suggested hyperparameters.\n",
        "3. Evaluate the model on a validation set\n",
        "4. Return the metric to minimize (loss) or maximize (accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    #############################\n",
        "    # All Hyperparameters Tested\n",
        "    #############################\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'AdamW'])\n",
        "    momentum = trial.suggest_float('momentum', 0.0, 0.99) if optimizer_name in ['SGD'] else 0.0\n",
        "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.01)\n",
        "    hidden_size = trial.suggest_int('hidden_size', 64, 256)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
        "    num_epochs = trial.suggest_int('num_epochs', 5, 10)\n",
        "    fc_drop_rate = trial.suggest_float('fc_drop_rate', 0.2, 0.6)\n",
        "    cnn_drop_rate = trial.suggest_float('cnn_drop_rate', 0.0, 0.3)\n",
        "\n",
        "    #####################\n",
        "    # Define the Model\n",
        "    #####################\n",
        "    class VideoGasNet(nn.Module):\n",
        "        def __init__(self, num_metadata_feats = 2, fc_drop_rate = 0.3, cnn_drop_rate = 0.3):\n",
        "            super(VideoGasNet, self).__init__()\n",
        "\n",
        "            self.conv1    = nn.Conv2d(2, 32, kernel_size=3, padding=1)\n",
        "            self.bn1      = nn.BatchNorm2d(32)\n",
        "            self.relu1    = nn.ReLU()\n",
        "            self.pool1    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.dropout1 = nn.Dropout2d(cnn_drop_rate)\n",
        "\n",
        "            self.conv2    = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "            self.bn2      = nn.BatchNorm2d(64)\n",
        "            self.relu2    = nn.ReLU()\n",
        "            self.pool2    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.dropout2 = nn.Dropout2d(cnn_drop_rate)\n",
        "\n",
        "            self.conv3    = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "            self.bn3      = nn.BatchNorm2d(128)\n",
        "            self.relu3    = nn.ReLU()\n",
        "            self.pool3    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.dropout3 = nn.Dropout2d(cnn_drop_rate)\n",
        "\n",
        "            # Original VGN had 4 blocks, performance seems to drop with additional\n",
        "            # blocks, testing current architecture before uncommenting this\n",
        "            # self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "            # self.relu4 = nn.ReLU()\n",
        "            # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "            # Calculate flatten size from conv layers from input(240x320)\n",
        "            # flatten_size = 128 * (240 // 8) * (320 // 8)\n",
        "            # 2^3 = 8 use for every conv + relu + pool block\n",
        "            # If adding more blocks multiply another 2 (2^4 = 16 for for blocks)\n",
        "            cnn_flatten_size = 128 * (240 // 8) * (320 // 8)\n",
        "\n",
        "            self.metadata_fc1 = nn.Linear(num_metadata_feats, 64)\n",
        "            self.metadata_bn1 = nn.BatchNorm1d(64)\n",
        "            self.metadata_relu1 = nn.ReLU()\n",
        "            self.metadata_dropout = nn.Dropout(fc_drop_rate)\n",
        "\n",
        "            # Append the metadata to the fully connected layer\n",
        "            combined_size = cnn_flatten_size + 64\n",
        "\n",
        "            self.fc1 = nn.Linear(combined_size, hidden_size)\n",
        "            self.bn4 = nn.BatchNorm1d(hidden_size)\n",
        "            self.relu4 = nn.ReLU()\n",
        "            self.dropout4 = nn.Dropout(fc_drop_rate)\n",
        "            self.fc2 = nn.Linear(hidden_size, 8)\n",
        "\n",
        "        def forward(self, image, metadata):\n",
        "            # Convolutional Blocks\n",
        "            x = self.dropout1(self.pool1(self.relu1(self.bn1(self.conv1(image)))))\n",
        "            x = self.dropout2(self.pool2(self.relu2(self.bn2(self.conv2(x)))))\n",
        "            x = self.dropout3(self.pool3(self.relu3(self.bn3(self.conv3(x)))))\n",
        "\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "            # Metadata from json blocks\n",
        "            meta = self.metadata_relu1(self.metadata_bn1(self.metadata_fc1(metadata)))\n",
        "            meta = self.metadata_dropout(meta)\n",
        "\n",
        "            # concatenate and flatten\n",
        "            combined = torch.cat([x, meta], dim=1)\n",
        "\n",
        "            # Fully Connected Blocks (Neural Network)\n",
        "            combined = self.relu4(self.bn4(self.fc1(combined)))\n",
        "            combined = self.dropout4(combined)\n",
        "            output = self.fc2(combined)\n",
        "\n",
        "            return output\n",
        "\n",
        "    model = VideoGasNet(num_metadata_feats = 2, fc_drop_rate=fc_drop_rate, cnn_drop_rate=cnn_drop_rate)\n",
        "\n",
        "    ###############################\n",
        "    # Define optimizer\n",
        "    ###############################\n",
        "    if optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'AdamW':\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'Adadelta':\n",
        "        optimizer = optim.Adadelta(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == \"Muon\":\n",
        "        optimizer = optim.Muon(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer name: {optimizer_name}\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ##########################################\n",
        "    # Create DataLoaders with trial batch_size\n",
        "    ##########################################\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    ###############################\n",
        "    # Train the model\n",
        "    ###############################\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Trial {trial.number} | lr={lr:.6f} | optimizer={optimizer_name} | \"\n",
        "          f\"batch={batch_size} | hidden={hidden_size}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for images, metadata, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            metadata = metadata.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, metadata)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        #Print out training during each epoch\n",
        "        train_accuracy = train_correct / train_total\n",
        "\n",
        "        # Print training accuracy for this epoch\n",
        "        print(f\"Epoch [{epoch+1:2d}/{num_epochs} ] Train Acc: {train_accuracy:.4f}\")\n",
        "\n",
        "    #####################\n",
        "    # Evaluate the model\n",
        "    #####################\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for images, metadata, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            metadata = metadata.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images, metadata)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    print(f\"Validation Acc: {accuracy:.4f}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "j853XWwKcO6L"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85b6636f"
      },
      "source": [
        "## Run the Optuna Study\n",
        "\n",
        "Now we will create an Optuna study and run the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8544ffd4",
        "outputId": "aaaf3197-55b2-43be-ac1e-52b621a630e7"
      },
      "source": [
        "# Create a study object and specify the direction of optimization (maximize accuracy)\n",
        "study = optuna.create_study(direction='maximize',\n",
        "                             pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))\n",
        "\n",
        "# Run the optimization\n",
        "study.optimize(objective, n_trials = 30)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best hyperparameters: \", study.best_params)\n",
        "\n",
        "# Print the best accuracy found\n",
        "print(\"Best accuracy: \", study.best_value)\n",
        "\n",
        "# Plot the visualization\n",
        "optuna.visualization.plot_param_importances(study).show()\n",
        "\n",
        "# Run more trials\n",
        "# study.optimize(objective, n_trials=20)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-02 20:06:17,492] A new study created in memory with name: no-name-ea706092-424e-4c8d-b485-8018e86bfd02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Trial 0 | lr=0.000121 | optimizer=AdamW | batch=128 | hidden=177\n",
            "======================================================================\n",
            "Epoch [ 1/7 ] Train Acc: 0.5470\n",
            "Epoch [ 2/7 ] Train Acc: 0.7730\n",
            "Epoch [ 3/7 ] Train Acc: 0.8745\n",
            "Epoch [ 4/7 ] Train Acc: 0.9222\n",
            "Epoch [ 5/7 ] Train Acc: 0.9418\n",
            "Epoch [ 6/7 ] Train Acc: 0.9556\n",
            "Epoch [ 7/7 ] Train Acc: 0.9645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-02 20:35:44,382] Trial 0 finished with value: 0.31391830559757944 and parameters: {'lr': 0.000120894002107495, 'optimizer': 'AdamW', 'weight_decay': 0.0005898044823550142, 'hidden_size': 177, 'batch_size': 128, 'num_epochs': 7, 'fc_drop_rate': 0.41887942963349045, 'cnn_drop_rate': 0.05499558346634281}. Best is trial 0 with value: 0.31391830559757944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Acc: 0.3139\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 1 | lr=0.038477 | optimizer=RMSprop | batch=32 | hidden=130\n",
            "======================================================================\n",
            "Epoch [ 1/10 ] Train Acc: 0.1264\n",
            "Epoch [ 2/10 ] Train Acc: 0.1282\n",
            "Epoch [ 3/10 ] Train Acc: 0.1247\n",
            "Epoch [ 4/10 ] Train Acc: 0.1278\n",
            "Epoch [ 5/10 ] Train Acc: 0.1264\n",
            "Epoch [ 6/10 ] Train Acc: 0.1242\n",
            "Epoch [ 7/10 ] Train Acc: 0.1260\n",
            "Epoch [ 8/10 ] Train Acc: 0.1232\n",
            "Epoch [ 9/10 ] Train Acc: 0.1246\n",
            "Epoch [10/10 ] Train Acc: 0.1239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-02 21:16:44,771] Trial 1 finished with value: 0.12427058569267344 and parameters: {'lr': 0.038477129729780964, 'optimizer': 'RMSprop', 'momentum': 0.7945351558191214, 'weight_decay': 0.0029810145884405772, 'hidden_size': 130, 'batch_size': 32, 'num_epochs': 10, 'fc_drop_rate': 0.21933425376416027, 'cnn_drop_rate': 0.013911218331316}. Best is trial 0 with value: 0.31391830559757944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Acc: 0.1243\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 2 | lr=0.000010 | optimizer=Adadelta | batch=16 | hidden=215\n",
            "======================================================================\n",
            "Epoch [ 1/5 ] Train Acc: 0.1388\n",
            "Epoch [ 2/5 ] Train Acc: 0.1585\n",
            "Epoch [ 3/5 ] Train Acc: 0.1781\n",
            "Epoch [ 4/5 ] Train Acc: 0.1925\n",
            "Epoch [ 5/5 ] Train Acc: 0.2018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-11-02 21:39:58,048] Trial 2 finished with value: 0.17397881996974282 and parameters: {'lr': 1.0054766400230084e-05, 'optimizer': 'Adadelta', 'weight_decay': 0.0085689481939001, 'hidden_size': 215, 'batch_size': 16, 'num_epochs': 5, 'fc_drop_rate': 0.3515580985452771, 'cnn_drop_rate': 0.11695352796637568}. Best is trial 0 with value: 0.31391830559757944.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Acc: 0.1740\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 3 | lr=0.001403 | optimizer=AdamW | batch=128 | hidden=123\n",
            "======================================================================\n",
            "Epoch [ 1/8 ] Train Acc: 0.4877\n",
            "Epoch [ 2/8 ] Train Acc: 0.7839\n",
            "Epoch [ 3/8 ] Train Acc: 0.8961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2025-11-02 21:53:35,898] Trial 3 failed with parameters: {'lr': 0.0014033867869529925, 'optimizer': 'AdamW', 'weight_decay': 0.005077267609769627, 'hidden_size': 123, 'batch_size': 128, 'num_epochs': 8, 'fc_drop_rate': 0.2513304325786173, 'cnn_drop_rate': 0.1759311401506968} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1905089268.py\", line 137, in objective\n",
            "    for images, metadata, labels in train_loader:\n",
            "                                    ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 734, in __next__\n",
            "    data = self._next_data()\n",
            "           ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 790, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/tmp/ipython-input-2954579682.py\", line 21, in __getitem__\n",
            "    image_data = np.load(numpy_path)\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\", line 484, in load\n",
            "    return format.read_array(fid, allow_pickle=allow_pickle,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/numpy/lib/format.py\", line 836, in read_array\n",
            "    array = numpy.fromfile(fp, dtype=dtype, count=count)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "[W 2025-11-02 21:53:35,942] Trial 3 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2751918197.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Run the optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Print the best hyperparameters found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    488\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \"\"\"\n\u001b[0;32m--> 490\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     ):\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1905089268.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mtrain_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2954579682.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m       \u001b[0mnumpy_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mimage_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    482\u001b[0m                                           max_header_size=max_header_size)\n\u001b[1;32m    483\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[1;32m    485\u001b[0m                                          \u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                                          max_header_size=max_header_size)\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0;31m# We can use the fast fromfile() function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0;31m# This is not a real file. We have to read it the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qAiydXPXgI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sources:\n",
        "###Hyperparameter Tuning with Optuna:\n",
        "https://medium.com/@taeefnajib/hyperparameter-tuning-using-optuna-c46d7b29a3e\n",
        "\n",
        "https://optuna.org/#code_examples\n",
        "###Multi-Modal ML Models\n",
        "https://www.nature.com/articles/s41598-025-14901-4\n",
        "https://www.reddit.com/r/MachineLearning/comments/nziumg/combining_images_and_other_numeric_features_in_a/\n",
        "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
        "\n",
        "###Next Models to test:\n",
        "VideoGasNet:\n",
        "https://www.sciencedirect.com/science/article/pii/S0360544221017643\n",
        "\n",
        "GasVit: https://www.sciencedirect.com/science/article/pii/S1568494623011560?via%3Dihub#sec3"
      ],
      "metadata": {
        "id": "QtEVZh5kKfpB"
      }
    }
  ]
}