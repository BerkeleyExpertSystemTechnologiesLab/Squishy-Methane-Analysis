{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BerkeleyExpertSystemTechnologiesLab/Squishy-Methane-Analysis/blob/jberry/Squish_Robot_Quant_Model_v6_1_5_Class%2Bimage_transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Description\n",
        "\n",
        "This model was produced by and for Squishy Robotics for the task of identifying and classifying methane leaks.\n",
        "\n",
        "\n",
        "This model was made in conjunction with a synthetic dataset of 2 channel, 240 by 320 greyscale images of methane leaks\n",
        "(2 x 240 x 320)\n",
        "The first channel is a greyscale background image and the second channel is a greyscale gas plume image.\n",
        "\n",
        "\n",
        "\n",
        "This model is experimental and uses the Optuna Hyperparameter Optimizer to search for successful hyperparameters (Learning Rate, Optimizer, Batch Size, Dropout %, etc...) and different optimizers. As such if you want to test a specific Model architecture you need to comment out the Optuna code and run a train/test on that specific model."
      ],
      "metadata": {
        "id": "Rf3vlYMJAK6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna #Hyperparameter Optimizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGzW9O1lKUhh",
        "outputId": "714859c9-d372-4ac6-ead1-160eb995c186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.44)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Hyperparameter Search Library\n",
        "import optuna\n",
        "\n",
        "import json\n",
        "import glob\n"
      ],
      "metadata": {
        "id": "tzEL-OHlG6G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "id": "n8JlSIL8-qyE"
      },
      "outputs": [],
      "source": [
        "# This may take several minutes, the synthetic dataset can be large\n",
        "!unzip -q Final_Dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c01635a9"
      },
      "source": [
        "## Print out the structure of the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading an example file to demonstrate the dimensions\n",
        "# This file might not exist, change the name to one that does to show the\n",
        "# dimensions\n",
        "file_path = './Final_Dataset/data/class_0/1237_frame_1004_class_0.npy'\n",
        "sample_data = np.load(file_path)\n",
        "print(f\"Shape of preprocessed sample data: {sample_data.shape}\")\n",
        "print(f\"Data type of preprocessed sample data: {sample_data.dtype}\")\n",
        "\n",
        "# GasVid synthetic processed dataset should be 2 channels, 240x320 in dimension"
      ],
      "metadata": {
        "id": "6dIk3Tx7GVXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8acdb31f-0dd6-4420-f7b6-1c01dd30838b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of preprocessed sample data: (2, 240, 320)\n",
            "Data type of preprocessed sample data: float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the data is in 'Final_Dataset/data' and class folders are named 'class_0' ... 'class_7'\n",
        "data_dir = 'Final_Dataset/data'\n",
        "classes = sorted(os.listdir(data_dir))\n",
        "print(f\"Classes: {classes}\")"
      ],
      "metadata": {
        "id": "Dqd6wbUTkgH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef23cf60-6ea4-4288-9520-fc9d51a666af"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fb4a66a"
      },
      "source": [
        "## Create a dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Multi_Modal_Dataset(Dataset):\n",
        "    def __init__(self, numpy_files, json_files, labels, transform=None):\n",
        "        \"\"\"\n",
        "        numpy_dir points to all the numpy 2 channel frames that were collected\n",
        "          from METEC. This is designed to be 1st Channel Greyscale image of\n",
        "          background, 2nd channel is just the gas plume scaled to some ppm\n",
        "        json_dir points to all the metadata (ppm, distance, etc) that was\n",
        "          collected from METEC or estimated using BEST Labs algorithms\n",
        "        \"\"\"\n",
        "        self.numpy_files = numpy_files\n",
        "        self.json_files = json_files\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.numpy_files)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      numpy_path = self.numpy_files[idx]\n",
        "      image_data = np.load(numpy_path)\n",
        "      image_tensor = torch.from_numpy(image_data).float()\n",
        "\n",
        "      if self.transform:\n",
        "        image_tensor = self.transform(image_tensor)\n",
        "\n",
        "      json_path = self.json_files[idx]\n",
        "      with open(json_path, 'r') as f:\n",
        "        metadata = json.load(f)\n",
        "\n",
        "      metadat_features = self._extract_metadata_features(metadata)\n",
        "      metadata_tensor = torch.tensor(metadat_features, dtype=torch.float32)\n",
        "\n",
        "      label = self.labels[idx]\n",
        "\n",
        "      return image_tensor, metadata_tensor, label\n",
        "\n",
        "\n",
        "    def _extract_metadata_features(self, metadata):\n",
        "      \"\"\"\n",
        "      Extracts a few entries from the metadata.\n",
        "        For now:\n",
        "          distance\n",
        "          ppm\n",
        "        In the future\n",
        "          windspeed\n",
        "          angle?\n",
        "      \"\"\"\n",
        "\n",
        "      features = []\n",
        "\n",
        "      # If the features exist, extract them, else place 0.0\n",
        "      # Print warning statements if unable to retrieve the data\n",
        "      distance = metadata.get(\"distance_m\", None)\n",
        "      if distance is None or distance == 0.0:\n",
        "          print(f\"WARNING: Invalid or missing distance_m value: {distance}\")\n",
        "          print(f\"  Metadata keys available: {list(metadata.keys())}\")\n",
        "          features.append(0.0)\n",
        "      else:\n",
        "          features.append(distance)\n",
        "\n",
        "      ppm = metadata.get(\"ppm\", None)\n",
        "      if ppm is None:\n",
        "          print(f\"WARNING: Missing ppm value\")\n",
        "          print(f\"  Metadata keys available: {list(metadata.keys())}\")\n",
        "          features.append(0.0)\n",
        "      else:\n",
        "          features.append(ppm)\n",
        "\n",
        "      return features"
      ],
      "metadata": {
        "id": "5JMbhRnSjMGa"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The GasVid dataset originally came with 8 classes of leak values\n",
        "# We are experimenting with reducing the number of classes to test\n",
        "# performance when the model has less differences between classes\n",
        "# This function takes the original classes and reduces them\n",
        "def map_class(original_class):\n",
        "    \"\"\"\n",
        "    Maps original 8-class labels to new 5-class labels\n",
        "    \"\"\"\n",
        "    class_mapping = {\n",
        "        0: 0,  # class_0 stays as class 0\n",
        "        1: 1,  # class_1 becomes class 1\n",
        "        2: 1,  # class_2 merged with class_1\n",
        "        3: 2,  # class_3 becomes class 2\n",
        "        4: 2,  # class_4 merged with class_3\n",
        "        5: 3,  # class_5 becomes class 3\n",
        "        6: 3,  # class_6 merged with class_5\n",
        "        7: 4   # class_7 becomes class 4\n",
        "    }\n",
        "    return class_mapping[original_class]"
      ],
      "metadata": {
        "id": "w9C-lYQP9xD4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_dir = \"./Final_Dataset/data\"\n",
        "json_dir = \"./Final_Dataset/metadata\"\n",
        "\n",
        "all_numpy_files = []\n",
        "all_json_files = []\n",
        "all_labels = []\n",
        "\n",
        "print(f\"Looking in: {numpy_dir}\")\n",
        "print(f\"Directory exists: {os.path.exists(numpy_dir)}\\n\")\n",
        "\n",
        "# Load each class separatley, collect the numpy and json files for a certain\n",
        "# class at the same time\n",
        "for class_idx in range(8):\n",
        "    numpy_class_dir = os.path.join(numpy_dir, f\"class_{class_idx}\")\n",
        "    json_class_dir = os.path.join(json_dir, f\"class_{class_idx}\")\n",
        "\n",
        "    numpy_files_in_class = sorted(glob.glob(os.path.join(numpy_class_dir, \"*.npy\")))\n",
        "\n",
        "    print(f\"Class {class_idx}: Found {len(numpy_files_in_class)} files\")\n",
        "\n",
        "    for numpy_file in numpy_files_in_class:\n",
        "        base_name = os.path.splitext(os.path.basename(numpy_file))[0]\n",
        "        video_id = base_name.split('_')[0]\n",
        "\n",
        "\n",
        "        json_filename = f\"{video_id}_class_{class_idx}.json\"\n",
        "        json_file = os.path.join(json_class_dir, json_filename)\n",
        "\n",
        "        if os.path.exists(json_file):\n",
        "            all_numpy_files.append(numpy_file)\n",
        "            all_json_files.append(json_file)\n",
        "            # Map the original class to the 5-class system\n",
        "            mapped_class = map_class(class_idx)\n",
        "            all_labels.append(mapped_class)\n",
        "        else:\n",
        "            print(f\"WARNING: JSON missing for {base_name}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"TOTAL: {len(all_numpy_files)} numpy files\")\n",
        "print(f\"TOTAL: {len(all_json_files)} json files\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Show distribution of mapped classes\n",
        "from collections import Counter\n",
        "class_distribution = Counter(all_labels)\n",
        "print(\"Class distribution after mapping (8 classes -> 5 classes):\")\n",
        "for cls in sorted(class_distribution.keys()):\n",
        "    print(f\"  Class {cls}: {class_distribution[cls]} samples\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Only continue if we have files\n",
        "if len(all_numpy_files) == 0:\n",
        "    raise ValueError(\"No files found! Check your paths above.\")\n",
        "\n",
        "# Now continue with video splitting\n",
        "video_to_indices = defaultdict(list)\n",
        "for idx, numpy_file in enumerate(all_numpy_files):\n",
        "    video_id = os.path.basename(numpy_file).split('_')[0]\n",
        "    video_to_indices[video_id].append(idx)\n",
        "\n",
        "print(f\"Number of unique videos: {len(video_to_indices)}\")\n",
        "print(f\"Video IDs: {sorted(video_to_indices.keys())}\\n\")\n"
      ],
      "metadata": {
        "id": "5__gzKDL2yqk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da1c2e4-1682-41e8-9acf-e4c2e81ede82"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in: ./Final_Dataset/data\n",
            "Directory exists: True\n",
            "\n",
            "Class 0: Found 5395 files\n",
            "Class 1: Found 5393 files\n",
            "Class 2: Found 5393 files\n",
            "Class 3: Found 5397 files\n",
            "Class 4: Found 5382 files\n",
            "Class 5: Found 5411 files\n",
            "Class 6: Found 5380 files\n",
            "Class 7: Found 5406 files\n",
            "\n",
            "============================================================\n",
            "TOTAL: 43157 numpy files\n",
            "TOTAL: 43157 json files\n",
            "============================================================\n",
            "\n",
            "Class distribution after mapping (8 classes -> 5 classes):\n",
            "  Class 0: 5395 samples\n",
            "  Class 1: 10786 samples\n",
            "  Class 2: 10779 samples\n",
            "  Class 3: 10791 samples\n",
            "  Class 4: 5406 samples\n",
            "============================================================\n",
            "\n",
            "Number of unique videos: 28\n",
            "Video IDs: ['1237', '1238', '1239', '1240', '1241', '1242', '1467', '1468', '1469', '1470', '1471', '1472', '2559', '2560', '2561', '2562', '2563', '2564', '2566', '2567', '2568', '2569', '2571', '2578', '2579', '2580', '2581', '2583']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_to_indices = defaultdict(list) #Make an empty dictionary of lists\n",
        "\n",
        "for idx, numpy_file in enumerate(all_numpy_files):\n",
        "    video_id = os.path.basename(numpy_file).split('_')[0] #Extract 4 digit code from numpy filename\n",
        "    video_to_indices[video_id].append(idx)\n",
        "\n",
        "video_ids = list(video_to_indices.keys())\n",
        "\n",
        "# Split the video into train and test\n",
        "train_vids, test_vids = train_test_split(video_ids, test_size=0.2, random_state=42)\n",
        "\n",
        "# Verify no overlap\n",
        "overlap = set(train_vids) & set(test_vids)\n",
        "if overlap:\n",
        "    print(f\"\\nVideos overlap: {overlap}\")\n",
        "else:\n",
        "    print(f\"\\nNo video overlap - train and test are separate\")\n",
        "\n",
        "train_indices = []\n",
        "test_indices = []\n",
        "\n",
        "for vid in train_vids:\n",
        "    train_indices.extend(video_to_indices[vid])\n",
        "for vid in test_vids:\n",
        "    test_indices.extend(video_to_indices[vid])\n",
        "\n",
        "# Create file lists\n",
        "train_numpy = [all_numpy_files[i] for i in train_indices]\n",
        "train_json = [all_json_files[i] for i in train_indices]\n",
        "train_labels_list = [all_labels[i] for i in train_indices]\n",
        "\n",
        "test_numpy = [all_numpy_files[i] for i in test_indices]\n",
        "test_json = [all_json_files[i] for i in test_indices]\n",
        "test_labels_list = [all_labels[i] for i in test_indices]\n"
      ],
      "metadata": {
        "id": "iNK0bdp8o9hM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71edf05-bf47-453a-80c1-3fb3ce1e3ce3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "No video overlap - train and test are separate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation section\n",
        "# https://docs.pytorch.org/vision/0.13/transforms.html\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=0,\n",
        "        translate=(0.1, 0.1),\n",
        "        scale=(0.9, 1.1),\n",
        "    ),\n",
        "    transforms.RandomApply([\n",
        "        transforms.GaussianBlur(\n",
        "            kernel_size=3,\n",
        "            sigma=(0.1, 2.0)\n",
        "        )\n",
        "    ], p=0.3)\n",
        "])\n",
        "\n",
        "#During testing don't use augmentation\n",
        "test_transforms = None"
      ],
      "metadata": {
        "id": "URAkjASnxIkS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW FINAL SPLIT STATISTICS\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"DATASET STATISTICS\")\n",
        "print(\"=\"*90)\n",
        "\n",
        "print(f\"\\nTRAINING SET:\")\n",
        "print(f\"   Total samples: {len(train_numpy)}\")\n",
        "print(f\"   From {len(train_vids)} videos: {sorted(train_vids)}\")\n",
        "\n",
        "# Count samples per class in training\n",
        "train_class_counts = Counter(train_labels_list)\n",
        "print(f\"\\n   Samples per class:\")\n",
        "for class_id in range(8):\n",
        "    count = train_class_counts.get(class_id, 0)\n",
        "    percentage = (count / len(train_numpy) * 100) if len(train_numpy) > 0 else 0\n",
        "    print(f\"      Class {class_id}: {count:5d} samples ({percentage:5.2f}%)\")\n",
        "\n",
        "print(f\"\\nTEST SET:\")\n",
        "print(f\"   Total samples: {len(test_numpy)}\")\n",
        "print(f\"   From {len(test_vids)} videos: {sorted(test_vids)}\")\n",
        "\n",
        "# Count samples per class in testing\n",
        "test_class_counts = Counter(test_labels_list)\n",
        "print(f\"\\n   Samples per class:\")\n",
        "for class_id in range(8):\n",
        "    count = test_class_counts.get(class_id, 0)\n",
        "    percentage = (count / len(test_numpy) * 100) if len(test_numpy) > 0 else 0\n",
        "    print(f\"      Class {class_id}: {count:5d} samples ({percentage:5.2f}%)\")\n",
        "\n",
        "# VERIFY ALL CLASSES PRESENT\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "train_classes = set(train_labels_list)\n",
        "test_classes = set(test_labels_list)\n",
        "missing_train = set(range(8)) - train_classes\n",
        "missing_test = set(range(8)) - test_classes\n",
        "\n",
        "if missing_train:\n",
        "    print(f\"WARNING: Training missing classes {missing_train}\")\n",
        "else:\n",
        "    print(f\"Training set has all 8 classes\")\n",
        "\n",
        "if missing_test:\n",
        "    print(f\"WARNING: Testing missing classes {missing_test}\")\n",
        "else:\n",
        "    print(f\"Test set has all 8 classes\")\n",
        "\n",
        "# Show train/test split ratio\n",
        "total_samples = len(train_numpy) + len(test_numpy)\n",
        "train_ratio = len(train_numpy) / total_samples * 100\n",
        "test_ratio = len(test_numpy) / total_samples * 100\n",
        "print(f\"\\nSplit ratio: {train_ratio:.1f}% train / {test_ratio:.1f}% test\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"DATA SPLIT COMPLETE AND VERIFIED\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "id": "OnsZFZCrETks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c20592c-1db1-4c02-b449-f13436814be8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DATASET STATISTICS\n",
            "==========================================================================================\n",
            "\n",
            "TRAINING SET:\n",
            "   Total samples: 33903\n",
            "   From 22 videos: ['1238', '1239', '1240', '1241', '1242', '1467', '1468', '1471', '1472', '2560', '2561', '2562', '2563', '2564', '2566', '2567', '2568', '2571', '2578', '2579', '2581', '2583']\n",
            "\n",
            "   Samples per class:\n",
            "      Class 0:  4232 samples (12.48%)\n",
            "      Class 1:  8474 samples (24.99%)\n",
            "      Class 2:  8475 samples (25.00%)\n",
            "      Class 3:  8479 samples (25.01%)\n",
            "      Class 4:  4243 samples (12.52%)\n",
            "      Class 5:     0 samples ( 0.00%)\n",
            "      Class 6:     0 samples ( 0.00%)\n",
            "      Class 7:     0 samples ( 0.00%)\n",
            "\n",
            "TEST SET:\n",
            "   Total samples: 9254\n",
            "   From 6 videos: ['1237', '1469', '1470', '2559', '2569', '2580']\n",
            "\n",
            "   Samples per class:\n",
            "      Class 0:  1163 samples (12.57%)\n",
            "      Class 1:  2312 samples (24.98%)\n",
            "      Class 2:  2304 samples (24.90%)\n",
            "      Class 3:  2312 samples (24.98%)\n",
            "      Class 4:  1163 samples (12.57%)\n",
            "      Class 5:     0 samples ( 0.00%)\n",
            "      Class 6:     0 samples ( 0.00%)\n",
            "      Class 7:     0 samples ( 0.00%)\n",
            "\n",
            "======================================================================\n",
            "VERIFICATION\n",
            "======================================================================\n",
            "WARNING: Training missing classes {5, 6, 7}\n",
            "WARNING: Testing missing classes {5, 6, 7}\n",
            "\n",
            "Split ratio: 78.6% train / 21.4% test\n",
            "\n",
            "======================================================================\n",
            "DATA SPLIT COMPLETE AND VERIFIED\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Multi_Modal_Dataset(train_numpy,\n",
        "                                    train_json,\n",
        "                                    train_labels_list,\n",
        "                                    transform=train_transforms)\n",
        "test_dataset = Multi_Modal_Dataset(test_numpy,\n",
        "                                   test_json,\n",
        "                                   test_labels_list,\n",
        "                                   transform=test_transforms)"
      ],
      "metadata": {
        "id": "z8GY3A5zprqh"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812eecda"
      },
      "source": [
        "# Define the CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5afeb9da"
      },
      "source": [
        "## Define the Optuna Objective Function\n",
        "\n",
        "This function will be called by Optuna for each trial. It will:\n",
        "1. Suggest hyperparameters using the trial object.\n",
        "2. Build and train the CNN model with the suggested hyperparameters.\n",
        "3. Evaluate the model on a validation set\n",
        "4. Return the metric to minimize (loss) or maximize (accuracy)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "\n",
        "    #############################\n",
        "    # All Hyperparameters Tested\n",
        "    #############################\n",
        "    lr = trial.suggest_float('lr', 1e-5, 1e-1, log=True)\n",
        "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'AdamW'])\n",
        "    momentum = trial.suggest_float('momentum', 0.0, 0.99) if optimizer_name in ['SGD'] else 0.0\n",
        "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.01)\n",
        "    hidden_size = trial.suggest_int('hidden_size', 64, 256)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
        "    num_epochs = trial.suggest_int('num_epochs', 5, 10)\n",
        "    fc_drop_rate = trial.suggest_float('fc_drop_rate', 0.2, 0.6)\n",
        "    cnn_drop_rate = trial.suggest_float('cnn_drop_rate', 0.0, 0.3)\n",
        "\n",
        "    #####################\n",
        "    # Define the Model\n",
        "    #####################\n",
        "    class VideoGasNet(nn.Module):\n",
        "        def __init__(self, num_metadata_feats = 2, fc_drop_rate = 0.3, cnn_drop_rate = 0.3):\n",
        "            super(VideoGasNet, self).__init__()\n",
        "\n",
        "            self.conv1    = nn.Conv2d(2, 32, kernel_size=3, padding=1)\n",
        "            self.bn1      = nn.BatchNorm2d(32)\n",
        "            self.relu1    = nn.ReLU()\n",
        "            self.pool1    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.dropout1 = nn.Dropout2d(cnn_drop_rate)\n",
        "\n",
        "            self.conv2    = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "            self.bn2      = nn.BatchNorm2d(64)\n",
        "            self.relu2    = nn.ReLU()\n",
        "            self.pool2    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.dropout2 = nn.Dropout2d(cnn_drop_rate)\n",
        "\n",
        "            self.conv3    = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "            self.bn3      = nn.BatchNorm2d(128)\n",
        "            self.relu3    = nn.ReLU()\n",
        "            self.pool3    = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "            self.dropout3 = nn.Dropout2d(cnn_drop_rate)\n",
        "\n",
        "            # Original VGN had 4 blocks, performance seems to drop with additional\n",
        "            # blocks, testing current architecture before uncommenting this\n",
        "            # self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "            # self.relu4 = nn.ReLU()\n",
        "            # self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "            # Calculate flatten size from conv layers from input(240x320)\n",
        "            # flatten_size = 128 * (240 // 8) * (320 // 8)\n",
        "            # 2^3 = 8 use for every conv + relu + pool block\n",
        "            # If adding more blocks multiply another 2 (2^4 = 16 for for blocks)\n",
        "            cnn_flatten_size = 128 * (240 // 8) * (320 // 8)\n",
        "\n",
        "            self.metadata_fc1 = nn.Linear(num_metadata_feats, 64)\n",
        "            self.metadata_bn1 = nn.BatchNorm1d(64)\n",
        "            self.metadata_relu1 = nn.ReLU()\n",
        "            self.metadata_dropout = nn.Dropout(fc_drop_rate)\n",
        "\n",
        "            # Append the metadata to the fully connected layer\n",
        "            combined_size = cnn_flatten_size + 64\n",
        "\n",
        "            self.fc1 = nn.Linear(combined_size, hidden_size)\n",
        "            self.bn4 = nn.BatchNorm1d(hidden_size)\n",
        "            self.relu4 = nn.ReLU()\n",
        "            self.dropout4 = nn.Dropout(fc_drop_rate)\n",
        "            self.fc2 = nn.Linear(hidden_size, 8)\n",
        "\n",
        "        def forward(self, image, metadata):\n",
        "            # Convolutional Blocks\n",
        "            x = self.dropout1(self.pool1(self.relu1(self.bn1(self.conv1(image)))))\n",
        "            x = self.dropout2(self.pool2(self.relu2(self.bn2(self.conv2(x)))))\n",
        "            x = self.dropout3(self.pool3(self.relu3(self.bn3(self.conv3(x)))))\n",
        "\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "            # Metadata from json blocks\n",
        "            meta = self.metadata_relu1(self.metadata_bn1(self.metadata_fc1(metadata)))\n",
        "            meta = self.metadata_dropout(meta)\n",
        "\n",
        "            # concatenate and flatten\n",
        "            combined = torch.cat([x, meta], dim=1)\n",
        "\n",
        "            # Fully Connected Blocks (Neural Network)\n",
        "            combined = self.relu4(self.bn4(self.fc1(combined)))\n",
        "            combined = self.dropout4(combined)\n",
        "            output = self.fc2(combined)\n",
        "\n",
        "            return output\n",
        "\n",
        "    model = VideoGasNet(num_metadata_feats = 2, fc_drop_rate=fc_drop_rate, cnn_drop_rate=cnn_drop_rate)\n",
        "\n",
        "    ###############################\n",
        "    # Define optimizer\n",
        "    ###############################\n",
        "    if optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'RMSprop':\n",
        "        optimizer = optim.RMSprop(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'AdamW':\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == 'Adadelta':\n",
        "        optimizer = optim.Adadelta(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    elif optimizer_name == \"Muon\":\n",
        "        optimizer = optim.Muon(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer name: {optimizer_name}\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    ##########################################\n",
        "    # Create DataLoaders with trial batch_size\n",
        "    ##########################################\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    ###############################\n",
        "    # Train the model\n",
        "    ###############################\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Trial {trial.number} | lr={lr:.6f} | optimizer={optimizer_name} | \"\n",
        "          f\"batch={batch_size} | hidden={hidden_size}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "        train_loss = 0.0\n",
        "        num_batches = 0\n",
        "\n",
        "        for images, metadata, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            metadata = metadata.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images, metadata)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Calculate loss\n",
        "            train_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "            # Calculate training accuracy\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        #Print out training during each epoch\n",
        "        train_accuracy = train_correct / train_total\n",
        "        avg_train_loss = train_loss / num_batches\n",
        "\n",
        "        # Print training accuracy for this epoch\n",
        "        print(f\"Epoch [{epoch+1:2d}/{num_epochs}] Train Loss: {avg_train_loss:.4f} | Train Acc: {train_accuracy:.4f}\")\n",
        "\n",
        "    #####################\n",
        "    # Evaluate the model\n",
        "    #####################\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    val_loss = 0.0\n",
        "    num_val_batches = 0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for images, metadata, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            metadata = metadata.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Calculate validation loss\n",
        "            outputs = model(images, metadata)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            num_val_batches += 1\n",
        "\n",
        "            # Calculate Validation Accuract\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    avg_val_loss = val_loss / num_val_batches\n",
        "\n",
        "    print(f\"Validation Loss: {avg_val_loss:.4f} | Validation Acc: {accuracy:.4f}\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "j853XWwKcO6L"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85b6636f"
      },
      "source": [
        "## Run the Optuna Study\n",
        "\n",
        "Now we will create an Optuna study and run the optimization process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8544ffd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c87ac1f-a5cc-4b1c-aa8f-8366b67243f2"
      },
      "source": [
        "# Create a study object and specify the direction of optimization (maximize accuracy)\n",
        "study = optuna.create_study(direction='maximize',\n",
        "                             pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=5))\n",
        "\n",
        "# Run the optimization\n",
        "study.optimize(objective, n_trials = 30)\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(\"Best hyperparameters: \", study.best_params)\n",
        "\n",
        "# Print the best accuracy found\n",
        "print(\"Best accuracy: \", study.best_value)\n",
        "\n",
        "# Plot the visualization\n",
        "optuna.visualization.plot_param_importances(study).show()\n",
        "\n",
        "# Run more trials\n",
        "# study.optimize(objective, n_trials=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 18:49:26,659] A new study created in memory with name: no-name-42fd6098-f4e1-4463-b40b-147fa665a945\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "Trial 0 | lr=0.000017 | optimizer=AdamW | batch=16 | hidden=144\n",
            "======================================================================\n",
            "Epoch [ 1/10] Train Loss: 1.7259 | Train Acc: 0.3134\n",
            "Epoch [ 2/10] Train Loss: 1.4124 | Train Acc: 0.3910\n",
            "Epoch [ 3/10] Train Loss: 1.3064 | Train Acc: 0.4180\n",
            "Epoch [ 4/10] Train Loss: 1.2445 | Train Acc: 0.4450\n",
            "Epoch [ 5/10] Train Loss: 1.1936 | Train Acc: 0.4618\n",
            "Epoch [ 6/10] Train Loss: 1.1601 | Train Acc: 0.4756\n",
            "Epoch [ 7/10] Train Loss: 1.1256 | Train Acc: 0.4884\n",
            "Epoch [ 8/10] Train Loss: 1.1045 | Train Acc: 0.5018\n",
            "Epoch [ 9/10] Train Loss: 1.0834 | Train Acc: 0.5099\n",
            "Epoch [10/10] Train Loss: 1.0628 | Train Acc: 0.5184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 20:16:28,850] Trial 0 finished with value: 0.5866652258482818 and parameters: {'lr': 1.7369916868841855e-05, 'optimizer': 'AdamW', 'weight_decay': 0.0029329877281740226, 'hidden_size': 144, 'batch_size': 16, 'num_epochs': 10, 'fc_drop_rate': 0.5976307380202674, 'cnn_drop_rate': 0.09211442911005796}. Best is trial 0 with value: 0.5866652258482818.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0513 | Validation Acc: 0.5867\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 1 | lr=0.000359 | optimizer=AdamW | batch=64 | hidden=143\n",
            "======================================================================\n",
            "Epoch [ 1/9] Train Loss: 1.2385 | Train Acc: 0.4568\n",
            "Epoch [ 2/9] Train Loss: 0.9598 | Train Acc: 0.5648\n",
            "Epoch [ 3/9] Train Loss: 0.8328 | Train Acc: 0.6261\n",
            "Epoch [ 4/9] Train Loss: 0.7624 | Train Acc: 0.6576\n",
            "Epoch [ 5/9] Train Loss: 0.7100 | Train Acc: 0.6829\n",
            "Epoch [ 6/9] Train Loss: 0.6541 | Train Acc: 0.7098\n",
            "Epoch [ 7/9] Train Loss: 0.6262 | Train Acc: 0.7222\n",
            "Epoch [ 8/9] Train Loss: 0.6016 | Train Acc: 0.7351\n",
            "Epoch [ 9/9] Train Loss: 0.5664 | Train Acc: 0.7508\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 21:31:03,652] Trial 1 finished with value: 0.6276204884374325 and parameters: {'lr': 0.00035904430160941104, 'optimizer': 'AdamW', 'weight_decay': 0.0020818289613160714, 'hidden_size': 143, 'batch_size': 64, 'num_epochs': 9, 'fc_drop_rate': 0.24145527703458158, 'cnn_drop_rate': 0.04297074415862845}. Best is trial 1 with value: 0.6276204884374325.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.0163 | Validation Acc: 0.6276\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 2 | lr=0.000695 | optimizer=SGD | batch=64 | hidden=162\n",
            "======================================================================\n",
            "Epoch [ 1/7] Train Loss: 1.5685 | Train Acc: 0.3498\n",
            "Epoch [ 2/7] Train Loss: 1.3026 | Train Acc: 0.4343\n",
            "Epoch [ 3/7] Train Loss: 1.2012 | Train Acc: 0.4748\n",
            "Epoch [ 4/7] Train Loss: 1.1384 | Train Acc: 0.5010\n",
            "Epoch [ 5/7] Train Loss: 1.0849 | Train Acc: 0.5185\n",
            "Epoch [ 6/7] Train Loss: 1.0442 | Train Acc: 0.5386\n",
            "Epoch [ 7/7] Train Loss: 1.0071 | Train Acc: 0.5571\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 22:28:50,171] Trial 2 finished with value: 0.4242489734169008 and parameters: {'lr': 0.0006949148350634561, 'optimizer': 'SGD', 'momentum': 0.554405575051173, 'weight_decay': 0.007522581447619235, 'hidden_size': 162, 'batch_size': 64, 'num_epochs': 7, 'fc_drop_rate': 0.21855811658640412, 'cnn_drop_rate': 0.06322843745280705}. Best is trial 1 with value: 0.6276204884374325.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 1.2133 | Validation Acc: 0.4242\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 3 | lr=0.000098 | optimizer=Adam | batch=32 | hidden=143\n",
            "======================================================================\n",
            "Epoch [ 1/9] Train Loss: 1.5771 | Train Acc: 0.3264\n",
            "Epoch [ 2/9] Train Loss: 1.3220 | Train Acc: 0.4096\n",
            "Epoch [ 3/9] Train Loss: 1.2397 | Train Acc: 0.4413\n",
            "Epoch [ 4/9] Train Loss: 1.1788 | Train Acc: 0.4644\n",
            "Epoch [ 5/9] Train Loss: 1.1315 | Train Acc: 0.4914\n",
            "Epoch [ 6/9] Train Loss: 1.0965 | Train Acc: 0.5064\n",
            "Epoch [ 7/9] Train Loss: 1.0564 | Train Acc: 0.5288\n",
            "Epoch [ 8/9] Train Loss: 1.0281 | Train Acc: 0.5441\n",
            "Epoch [ 9/9] Train Loss: 0.9968 | Train Acc: 0.5561\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[I 2025-11-14 23:42:54,787] Trial 3 finished with value: 0.558353144586125 and parameters: {'lr': 9.765352775742062e-05, 'optimizer': 'Adam', 'weight_decay': 0.00840788221347079, 'hidden_size': 143, 'batch_size': 32, 'num_epochs': 9, 'fc_drop_rate': 0.46458506397698224, 'cnn_drop_rate': 0.2614817840464674}. Best is trial 1 with value: 0.6276204884374325.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 0.9608 | Validation Acc: 0.5584\n",
            "======================================================================\n",
            "\n",
            "\n",
            "======================================================================\n",
            "Trial 4 | lr=0.006460 | optimizer=SGD | batch=64 | hidden=218\n",
            "======================================================================\n",
            "Epoch [ 1/9] Train Loss: 1.2126 | Train Acc: 0.4579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qAiydXPXgI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sources:\n",
        "###Hyperparameter Tuning with Optuna:\n",
        "https://medium.com/@taeefnajib/hyperparameter-tuning-using-optuna-c46d7b29a3e\n",
        "\n",
        "https://optuna.org/#code_examples\n",
        "###Multi-Modal ML Models\n",
        "https://www.nature.com/articles/s41598-025-14901-4\n",
        "https://www.reddit.com/r/MachineLearning/comments/nziumg/combining_images_and_other_numeric_features_in_a/\n",
        "https://pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/\n",
        "\n",
        "###Next Models to test:\n",
        "VideoGasNet:\n",
        "https://www.sciencedirect.com/science/article/pii/S0360544221017643\n",
        "\n",
        "GasVit: https://www.sciencedirect.com/science/article/pii/S1568494623011560?via%3Dihub#sec3"
      ],
      "metadata": {
        "id": "QtEVZh5kKfpB"
      }
    }
  ]
}