{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 15:15:51.521274: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-24 15:15:51.521300: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-24 15:15:51.521326: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import imageio\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_channels = 3 # actually there are three channels in this image\n",
    "num_classes = 1\n",
    "image_size = (240,320)\n",
    "latent_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_data_dir = '/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/frame_data_movingAvg/'\n",
    "frame_data_dir = '/home/bestlab/Desktop/Squishy-Methane-Analysis/0 - GasNet/frame_data_movingAvg/'\n",
    "frame_train_data_dir = os.path.join(frame_data_dir, 'train')\n",
    "frame_test_data_dir = os.path.join(frame_data_dir, 'test')\n",
    "frame_train_nonleak_data_dir = os.path.join(frame_train_data_dir,'Nonleaks')\n",
    "frame_train_leak_data_dir = os.path.join(frame_train_data_dir,'Leak')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data in training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we cannot load in both non leak and leak to generate pics, because they are originally inbalanced.  \n",
    "Let's try to import all the non-leak pics and down sample the leak pics to create a balanced set for GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 116180 files belonging to 1 classes.\n",
      "Found 163893 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "nonleak_frame_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=frame_train_nonleak_data_dir,\n",
    "    labels=None,\n",
    "    batch_size=32,\n",
    "    image_size=(240,320),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "leak_frame_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory = frame_train_leak_data_dir,\n",
    "    labels=None,\n",
    "    batch_size=32,\n",
    "    image_size=(240,320),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Down sample the leak set to the size of nonleak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3631\n",
      "3631\n"
     ]
    }
   ],
   "source": [
    "n_nonleak = len(nonleak_frame_dataset)\n",
    "print(n_nonleak)\n",
    "leak_frame_dataset_downsampled = leak_frame_dataset.take(n_nonleak)\n",
    "print(len(leak_frame_dataset_downsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# for images in leak_frame_dataset_downsampled.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3,3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title('leak')\n",
    "#         plt.tight_layout()\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# for images in nonleak_frame_dataset.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3,3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title('nonleak')\n",
    "#         plt.tight_layout()\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_digits = nonleak_frame_dataset.concatenate(leak_frame_dataset_downsampled)\n",
    "def generate_label(label,batch_size,dataset_size):\n",
    "    temp = np.array([[label]*batch_size]*dataset_size)\n",
    "    temp = temp.reshape((-1,32,1))\n",
    "    return temp.astype('float32')\n",
    "\n",
    "label_nonleak = tf.data.Dataset.from_tensor_slices(generate_label(0,32,n_nonleak))\n",
    "label_leak = tf.data.Dataset.from_tensor_slices(generate_label(1,32,n_nonleak))\n",
    "all_labels = label_nonleak.concatenate(label_leak)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((all_digits,all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the number of input channel for the generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 4\n"
     ]
    }
   ],
   "source": [
    "generator_in_channels = latent_dim + num_classes\n",
    "discriminator_in_channels = num_channels + num_classes\n",
    "print(generator_in_channels, discriminator_in_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the discriminator and generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the discriminator.\n",
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((240,320, discriminator_in_channels)),\n",
    "        layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.GlobalMaxPooling2D(),\n",
    "        layers.Dense(1),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "\n",
    "# Create the generator.\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.InputLayer((generator_in_channels,)),\n",
    "\n",
    "        layers.Dense(15 * 20 * generator_in_channels),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Reshape((15, 20, generator_in_channels)),\n",
    "        \n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        \n",
    "        layers.Conv2D(3, (7, 7), padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a ConditionalGAN model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "        \n",
    "    def get_config(self):\n",
    "            return {\n",
    "                \"discriminator_config\": self.discriminator.get_config(),\n",
    "                \"generator_config\": self.generator.get_config(),\n",
    "                \"latent_dim\": self.latent_dim,\n",
    "            }\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config,discriminator,generator):\n",
    "        discriminator = discriminator.from_config(config[\"discriminator_config\"])\n",
    "        generator = generator.from_config(config[\"generator_config\"])\n",
    "        return cls(discriminator=discriminator, generator=generator, latent_dim=config[\"latent_dim\"])\n",
    "\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def call(self, data):\n",
    "        x = self.forward(data)\n",
    "        return x\n",
    "    \n",
    "    def forward(self,data):\n",
    "        # Unpack the data.\n",
    "        real_images, one_hot_labels = data\n",
    "        # Add dummy dimensions to the labels so that they can be concatenated with\n",
    "        # the images. This is for the discriminator.\n",
    "        image_one_hot_labels = one_hot_labels[:, :, None, None]\n",
    "        image_one_hot_labels = tf.repeat(\n",
    "            image_one_hot_labels, repeats=[240 * 320]\n",
    "        )\n",
    "        image_one_hot_labels = tf.reshape(\n",
    "            image_one_hot_labels, (-1, 240, 320, num_classes)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space and concatenate the labels.\n",
    "        # This is for the generator.\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Decode the noise (guided by labels) to fake images.\n",
    "        generated_images = self.generator(random_vector_labels)\n",
    "\n",
    "        # Combine them with real images. Note that we are concatenating the labels\n",
    "        # with these images here.\n",
    "        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)\n",
    "        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)\n",
    "\n",
    "        combined_images = tf.concat(\n",
    "            [fake_image_and_labels, real_image_and_labels], axis=0\n",
    "        )\n",
    "\n",
    "        return combined_images,image_one_hot_labels\n",
    "    \n",
    "    def train_step(self, data):\n",
    "\n",
    "        real_images, one_hot_labels = data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        combined_images, image_one_hot_labels = self.forward(data)\n",
    "        \n",
    "        # Assemble labels discriminating real from fake images.\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        # Train the discriminator.\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space.\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        random_vector_labels = tf.concat(\n",
    "            [random_latent_vectors, one_hot_labels], axis=1\n",
    "        )\n",
    "\n",
    "        # Assemble labels that say \"all real images\".\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_images = self.generator(random_vector_labels)\n",
    "            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)\n",
    "            predictions = self.discriminator(fake_image_and_labels)\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "        return {\n",
    "            \"g_loss\": self.gen_loss_tracker.result(),\n",
    "            \"d_loss\": self.disc_loss_tracker.result(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan = ConditionalGAN(\n",
    "    discriminator=discriminator, generator=generator, latent_dim=latent_dim\n",
    ")\n",
    "cond_gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0003),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "for real_images, one_hot_labels in dataset.take(1):\n",
    "    cond_gan((real_images,one_hot_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_gan.fit(dataset, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbestlab/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39m1\u001b[39m\u001b[39m==\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbestlab/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m cond_gan\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./models/oct12-gan/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(1==3)\n",
    "cond_gan.save('./models/oct12-gan/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './models/oct12-gan/'\n",
    "cond_gan = tf.keras.models.load_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating fake nonleak images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first extract the trained generator from our Conditional GAN.\n",
    "trained_gen = cond_gan.generator\n",
    "number_nonleak = 42881\n",
    "number_leak = 304911\n",
    "number_diff = number_leak-number_nonleak\n",
    "number_gen = number_nonleak\n",
    "# Choose the number of intermediate images that would be generated in\n",
    "# between the interpolation + 2 (start and last images).\n",
    "num_images = number_gen  # @param {type:\"integer\"}\n",
    "\n",
    "# Sample noise for the interpolation.\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=num_images)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (num_images, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [10,128] vs. shape[1] = [10] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb Cell 25\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m start_class \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# @param {type:\"slider\", min:0, max:9, step:1}\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m end_class \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m  \u001b[39m# @param {type:\"slider\", min:0, max:9, step:1}\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m fake_images \u001b[39m=\u001b[39m generate_image(trained_gen,\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Here, we first sample noise from a normal distribution and then we repeat that for num_interpolation times \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# and reshape the result accordingly. We then distribute it uniformly for num_interpolation with the label \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# identities being present in some proportion.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m fake_images \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m255.0\u001b[39m\n",
      "\u001b[1;32m/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m interpolation_noise \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mreshape(interpolation_noise, (number_generation, latent_dim))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m labels \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mzeros(number_generation)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m noise_and_labels \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconcat([interpolation_noise, (labels)], \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m fake \u001b[39m=\u001b[39m trained_gen\u001b[39m.\u001b[39mpredict(noise_and_labels)    \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbestloft.me.berkeley.edu/home/bestlab/Desktop/DevEng-Squishy-Methane-Detection/EricMiao/MethaneGAN/GAN-augment.ipynb#X35sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mreturn\u001b[39;00m fake\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5886\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[1;32m   5887\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 5888\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:GPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [10,128] vs. shape[1] = [10] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# def interpolate_class(first_number, second_number):\n",
    "#     # Convert the start and end labels to one-hot encoded vectors.\n",
    "#     first_label = keras.utils.to_categorical([first_number], num_classes)\n",
    "#     second_label = keras.utils.to_categorical([second_number], num_classes)\n",
    "#     first_label = tf.cast(first_label, tf.float32)\n",
    "#     second_label = tf.cast(second_label, tf.float32)\n",
    "\n",
    "#     # Calculate the interpolation vector between the two labels.\n",
    "#     percent_second_label = tf.linspace(0, 1, num_images)[:, None]\n",
    "#     percent_second_label = tf.cast(percent_second_label, tf.float32)\n",
    "#     interpolation_labels = (\n",
    "#         first_label * (1 - percent_second_label) + second_label * percent_second_label\n",
    "#     )\n",
    "\n",
    "#     # Combine the noise and the labels and run inference with the generator.\n",
    "#     noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)\n",
    "#     fake = trained_gen.predict(noise_and_labels)\n",
    "#     return fake\n",
    "\n",
    "def generate_image(trained_gen,number_generation:int):\n",
    "    latent_dim = 128\n",
    "    interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "    interpolation_noise = tf.repeat(interpolation_noise, repeats=number_generation)\n",
    "    interpolation_noise = tf.reshape(interpolation_noise, (number_generation, latent_dim))\n",
    "\n",
    "\n",
    "    labels = tf.zeros((number_generation,1))\n",
    "    noise_and_labels = tf.concat([interpolation_noise, (labels)], 1)\n",
    "    fake = trained_gen.predict(noise_and_labels)    \n",
    "    return fake\n",
    "\n",
    "trained_gen = cond_gan.generator\n",
    "fake_images = generate_image(trained_gen,10)\n",
    "\n",
    "# Here, we first sample noise from a normal distribution and then we repeat that for num_interpolation times \n",
    "# and reshape the result accordingly. We then distribute it uniformly for num_interpolation with the label \n",
    "# identities being present in some proportion.\n",
    "\n",
    "fake_images *= 255.0\n",
    "converted_images = fake_images.astype(np.uint8)\n",
    "os.makedirs('generated_images', exist_ok=True)\n",
    "\n",
    "for i in range(num_images):\n",
    "    # Use imageio to save the image\n",
    "    imageio.imsave(f'generated_images/fake_nonleak_image_{i}.png', converted_images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 128\n",
    "number_generation=10\n",
    "interpolation_noise = tf.random.normal(shape=(1, latent_dim))\n",
    "interpolation_noise = tf.repeat(interpolation_noise, repeats=number_generation)\n",
    "interpolation_noise = tf.reshape(interpolation_noise, (number_generation, latent_dim))\n",
    "\n",
    "\n",
    "labels = tf.zeros((number_generation,1))\n",
    "noise_and_labels = tf.concat([interpolation_noise, labels], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
