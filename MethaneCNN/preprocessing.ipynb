{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements\n",
    "******Remember to restart the kernel after installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (23.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Ignoring tensorflow: markers 'sys_platform == \"linux\"' don't match your environment\n",
      "Ignoring tensorflow: markers 'sys_platform == \"windows\"' don't match your environment\n",
      "Ignoring tensorflow-macos: markers 'sys_platform == \"darwin\"' don't match your environment\n",
      "Requirement already satisfied: keras>=2.11.0 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from -r ../requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: pillow>=9.4.0 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from -r ../requirements.txt (line 5)) (9.5.0)\n",
      "Requirement already satisfied: opencv-python>=4.7.0.72 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from -r ../requirements.txt (line 6)) (4.7.0.72)\n",
      "Requirement already satisfied: scipy>=1.10.1 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from -r ../requirements.txt (line 7)) (1.10.1)\n",
      "Requirement already satisfied: matplotlib>=3.7.1 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from -r ../requirements.txt (line 8)) (3.7.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from -r ../requirements.txt (line 9)) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from opencv-python>=4.7.0.72->-r ../requirements.txt (line 6)) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from scikit-learn->-r ../requirements.txt (line 9)) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bestlab\\squishy-methane-analysis\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.7.1->-r ../requirements.txt (line 8)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_median(frames):\n",
    "    median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "    return median_frame\n",
    "\n",
    "def doMovingAverageBGS(image, prev_frames):\n",
    "    median_img = calc_median(prev_frames)\n",
    "    image = cv2.absdiff(image, median_img)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractImages(pathIn, pathOut, leakRange, nonleakRange, currCountLeak, currCountNonLeak):\n",
    "\n",
    "  '''\n",
    "  Input:\n",
    "    String: pathIn should be the path of the video \n",
    "    String: pathOut should be the path of the folder where data is being stored for testing or training\n",
    "    Tuple: range of leak frames from video\n",
    "    Tuple: range of nonleak frames from video\n",
    "\n",
    "  Output:\n",
    "    creates two subfolders in pathOut called Leaks and Nonleaks\n",
    "      Leaks folder contains the frames where there are leaks\n",
    "      Nonleaks folder contains the frames where there are noleaks\n",
    "  '''\n",
    "\n",
    "  leakPath = os.path.join(pathOut, \"Leak\")\n",
    "  nonleakPath = os.path.join(pathOut, \"Nonleaks\")\n",
    "  \n",
    "  os.makedirs(leakPath, exist_ok=True)\n",
    "  os.makedirs(nonleakPath, exist_ok=True)\n",
    "\n",
    "  def helper(pathIn, pathOut, range, isLeak, currCountLeak, currCountNonLeak):\n",
    "    '''\n",
    "    Might need to clean this up, but this was extracted from the original extractImages from the previous implementation\n",
    "    \n",
    "    '''\n",
    "    #setting up moving average list\n",
    "    prev_imgs = []\n",
    "    prev_limit = 210 #210 in paper\n",
    "\n",
    "    start = range[0] * 1000 # converting seconds to milliseconds\n",
    "    end = range[1] * 1000\n",
    "    cap = cv2.VideoCapture(pathIn)\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, start)\n",
    "    success = True\n",
    "\n",
    "    if cap.isOpened():\n",
    "      while success and start < end:  \n",
    "          success, image = cap.read()\n",
    "          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "          start = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "          if success:\n",
    "\n",
    "            prev_imgs.append(image)\n",
    "            if len(prev_imgs) > prev_limit:\n",
    "                prev_imgs.pop(0)\n",
    "          \n",
    "            processed_img = doMovingAverageBGS(image, prev_imgs) #to generalize might need to make this function as a parameter\n",
    "            \n",
    "            if isLeak:\n",
    "                cv2.imwrite(os.path.join(pathOut, \"leak.frame%d.jpg\" % currCountLeak), processed_img)     # save frame as JPEG file\n",
    "                currCountLeak += 1\n",
    "            else:\n",
    "                cv2.imwrite(os.path.join(pathOut, \"nonleak.frame%d.jpg\" % currCountNonLeak), processed_img)\n",
    "                currCountNonLeak += 1\n",
    "          else:\n",
    "            break\n",
    "      cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if isLeak:\n",
    "       return currCountLeak\n",
    "    else:\n",
    "       return currCountNonLeak\n",
    "  # call helper for both nonLeak and leak and get updated counts\n",
    "  updated_currCountNonLeak = helper(pathIn, nonleakPath, nonleakRange, isLeak=False, currCountLeak=currCountLeak, currCountNonLeak=currCountNonLeak)\n",
    "  updated_currCountLeak = helper(pathIn, leakPath, leakRange, isLeak=True,currCountLeak=currCountLeak, currCountNonLeak=currCountNonLeak)\n",
    "  \n",
    "  return updated_currCountNonLeak, updated_currCountLeak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get generic path to directory\n",
    "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "# get all raw video data directories\n",
    "data_dir = os.path.join(dir_path, 'data')\n",
    "\n",
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "test_data_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "frame_data_dir = os.path.join(dir_path, 'frame_data_movingAvg')\n",
    "frame_train_data_dir = os.path.join(frame_data_dir, 'train')\n",
    "frame_test_data_dir = os.path.join(frame_data_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Ranges for Each Video In GasVid (Excluding 18.6m and 8.8m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = np.loadtxt(os.path.join(dir_path, 'GasVid_Ranges_Seconds.csv'), skiprows=1, delimiter=',', dtype=int)\n",
    "\n",
    "ranges = list(zip(raw_data[:, 0], raw_data[:, 1:3], raw_data[:, 3:5])) #need to upload new ranges\n",
    "ranges = {ranges[i][0] : (ranges[i][1], ranges[i][2]) for i in range(len(ranges))}\n",
    "len(ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames_from_dir(dir_path, output_path, max_vids=None):\n",
    "    cur_count = 1\n",
    "    currNonLeakCount = 0\n",
    "    currLeakCount = 0\n",
    "    \n",
    "    for file in os.listdir(dir_path):\n",
    "        if max_vids and cur_count > max_vids:\n",
    "            break\n",
    "        vid_path = os.path.join(dir_path, file)\n",
    "        vid_id = int(os.path.basename(vid_path)[4:8])\n",
    "        if vid_id not in ranges.keys():\n",
    "            continue\n",
    "\n",
    "        nonleak_start = ranges[vid_id][0][0]\n",
    "        nonleak_end = ranges[vid_id][0][1]\n",
    "        leak_start = ranges[vid_id][1][0]\n",
    "        leak_end = ranges[vid_id][1][1]\n",
    "\n",
    "        currNonLeakCount, currLeakCount = extractImages(vid_path, output_path, (leak_start, leak_end), (nonleak_start, nonleak_end), currLeakCount, currNonLeakCount)\n",
    "        print(\"Video\", vid_id)\n",
    "        print(\"Current NonLeak Count\", currNonLeakCount)\n",
    "        print(\"Current Leak Count\", currLeakCount)\n",
    "\n",
    "        print('Done with', cur_count, \"video(s)\")\n",
    "        cur_count += 1\n",
    "    return currNonLeakCount, currLeakCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Frames from Data Directory and Setting Them in Frame Data Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 1237\n",
      "Current NonLeak Count 2387\n",
      "Current Leak Count 18473\n",
      "Done with 1 video(s)\n",
      "Video 1238\n",
      "Current NonLeak Count 4770\n",
      "Current Leak Count 36963\n",
      "Done with 2 video(s)\n",
      "Video 1239\n",
      "Current NonLeak Count 7162\n",
      "Current Leak Count 55437\n",
      "Done with 3 video(s)\n",
      "Video 1240\n",
      "Current NonLeak Count 9544\n",
      "Current Leak Count 73935\n",
      "Done with 4 video(s)\n",
      "Video 1242\n",
      "Current NonLeak Count 11929\n",
      "Current Leak Count 92423\n",
      "Done with 5 video(s)\n",
      "Video 2559\n",
      "Current NonLeak Count 14315\n",
      "Current Leak Count 110887\n",
      "Done with 6 video(s)\n",
      "Video 2560\n",
      "Current NonLeak Count 16692\n",
      "Current Leak Count 129340\n",
      "Done with 7 video(s)\n",
      "Video 2561\n",
      "Current NonLeak Count 19081\n",
      "Current Leak Count 147804\n",
      "Done with 8 video(s)\n",
      "Video 2562\n",
      "Current NonLeak Count 21465\n",
      "Current Leak Count 166264\n",
      "Done with 9 video(s)\n",
      "Video 2564\n",
      "Current NonLeak Count 23853\n",
      "Current Leak Count 184735\n",
      "Done with 10 video(s)\n",
      "Video 2566\n",
      "Current NonLeak Count 26236\n",
      "Current Leak Count 203211\n",
      "Done with 11 video(s)\n",
      "Video 2567\n",
      "Current NonLeak Count 28621\n",
      "Current Leak Count 221697\n",
      "Done with 12 video(s)\n",
      "Video 2568\n",
      "Current NonLeak Count 31006\n",
      "Current Leak Count 240174\n",
      "Done with 13 video(s)\n",
      "Video 2569\n",
      "Current NonLeak Count 33393\n",
      "Current Leak Count 258639\n",
      "Done with 14 video(s)\n",
      "Video 2570\n",
      "Current NonLeak Count 35779\n",
      "Current Leak Count 277114\n",
      "Done with 15 video(s)\n",
      "Done with Training Data\n",
      "Video 1467\n",
      "Current NonLeak Count 2384\n",
      "Current Leak Count 18480\n",
      "Done with 1 video(s)\n",
      "Video 1468\n",
      "Current NonLeak Count 4771\n",
      "Current Leak Count 36967\n",
      "Done with 2 video(s)\n",
      "Video 1469\n",
      "Current NonLeak Count 7155\n",
      "Current Leak Count 55452\n",
      "Done with 3 video(s)\n",
      "Video 1470\n",
      "Current NonLeak Count 9539\n",
      "Current Leak Count 73944\n",
      "Done with 4 video(s)\n",
      "Video 1471\n",
      "Current NonLeak Count 11932\n",
      "Current Leak Count 92441\n",
      "Done with 5 video(s)\n",
      "Video 2578\n",
      "Current NonLeak Count 14313\n",
      "Current Leak Count 110900\n",
      "Done with 6 video(s)\n",
      "Video 2579\n",
      "Current NonLeak Count 16697\n",
      "Current Leak Count 129346\n",
      "Done with 7 video(s)\n",
      "Video 2580\n",
      "Current NonLeak Count 19082\n",
      "Current Leak Count 147847\n",
      "Done with 8 video(s)\n",
      "Video 2581\n",
      "Current NonLeak Count 21467\n",
      "Current Leak Count 166326\n",
      "Done with 9 video(s)\n",
      "Video 2582\n",
      "Current NonLeak Count 23857\n",
      "Current Leak Count 184811\n",
      "Done with 10 video(s)\n",
      "Done with Testing Data\n"
     ]
    }
   ],
   "source": [
    "image_dim = (240, 320)\n",
    "vid_count = 15 #max =>15\n",
    "test_count = 10 #max =>10\n",
    "\n",
    "total_train_NonLeak, total_train_Leak = read_frames_from_dir(train_data_dir, frame_train_data_dir, vid_count)\n",
    "print(\"Done with Training Data\")\n",
    "total_test_NonLeak, total_test_Leak = read_frames_from_dir(test_data_dir, frame_test_data_dir, test_count)\n",
    "print(\"Done with Testing Data\")\n",
    "#weird bug in which it if vid_count is 1 goes on to the next one\n",
    "#might need to cut in amount of samples but we will see"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Generators for Training, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 250316 images belonging to 2 classes.\n",
      "Found 62577 images belonging to 2 classes.\n",
      "Found 208668 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "val_split = 0.2\n",
    "batch_size = 32\n",
    "target_size = (240, 320)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # featurewise_center=True, #cant do this as need entire dataset to do it | need to figure out a way in doing this\n",
    "    # featurewise_std_normalization=True,\n",
    "    rescale=1. / 255,\n",
    "    validation_split=val_split,\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=frame_train_data_dir,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"training\",\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=target_size\n",
    "\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    directory=frame_train_data_dir,\n",
    "    class_mode=\"binary\",\n",
    "    subset=\"validation\",\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=target_size\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    # featurewise_center=True,\n",
    "    # featurewise_std_normalization=True,\n",
    "    rescale=1. / 255,\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=frame_test_data_dir, \n",
    "    class_mode='binary', \n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    target_size=target_size\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 4.372578887056654, 0: 0.564556464126677}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonleaks = total_train_NonLeak\n",
    "leaks = total_train_Leak\n",
    "total = nonleaks + leaks\n",
    "\n",
    "weight_nonleak = (1 / nonleaks) * (total / 2.0)\n",
    "weight_leak = (1 / leaks) * (total / 2.0)\n",
    "\n",
    "class_weight = {train_generator.class_indices[\"Nonleaks\"]: weight_nonleak, train_generator.class_indices[\"Leak\"]: weight_leak}\n",
    "class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_mean(generators):\n",
    "    feature_sum = 0\n",
    "    num_elements = 0\n",
    "    for generator in generators: #had to include this as I am splitting training data with validation data\n",
    "        for data, _ in generator:\n",
    "            feature_sum += np.sum(data, axis=(0, 1, 2), dtype=np.float64)\n",
    "            num_elements += np.prod(data.shape[0:3], dtype=np.int64)\n",
    "        generator.reset()\n",
    "    return feature_sum/num_elements\n",
    "\n",
    "def generator_std(generators, mean):\n",
    "    sum_squared_diff = 0\n",
    "    num_elements = 0\n",
    "    for generator in generators: \n",
    "        for data, _ in generator:\n",
    "            squared_diff = (data - mean) ** 2\n",
    "            sum_squared_diff += np.sum(squared_diff, axis=(0, 1, 2), dtype=np.float64)\n",
    "            num_elements += np.prod(data.shape[0:3], dtype=np.int64)\n",
    "        generator.reset()\n",
    "    return np.sqrt(sum_squared_diff / (num_elements - 1), dtype=np.float64)\n",
    "\n",
    "def get_with_featurewise_center(generator, mean):\n",
    "    for data, labels in generator:\n",
    "        if mean:\n",
    "            data -= mean\n",
    "        yield data, labels\n",
    "\n",
    "def get_with_featurewise_std_norm(generator, std):\n",
    "    for data, labels in generator:\n",
    "        if std:\n",
    "            data /= (std + 1e-6)\n",
    "        yield data, labels\n",
    "\n",
    "def get_with_featurewise_center_std_norm (generator, mean, std):\n",
    "    for data, labels in generator:\n",
    "        if mean:\n",
    "            data -= mean\n",
    "        if std:\n",
    "            data /= (std + 1e-6)\n",
    "        yield data, labels\n",
    "\n",
    "def generate_stats(gens):\n",
    "    print(\"Calculating mean...\")\n",
    "    mean = generator_mean(generators=gens)\n",
    "    print(\"Done!\")\n",
    "    featwise_center_gens = [get_with_featurewise_center(gen, mean) for gen in gens]\n",
    "    print(\"Calculating std from centered data...\")\n",
    "    std = generator_std(generators=featwise_center_gens, mean=mean)\n",
    "    print(\"Done!\")\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = generate_stats([train_generator, val_generator])\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: calculate sample_weights using train_generator | should be similar to how predictions are made at the bottom of the notebook\n",
    "#I think this should work but not sure\n",
    "\n",
    "# A DirectoryIterator yielding tuples of (x, y) where x is a numpy array \n",
    "# containing a batch of images with shape (batch_size, *target_size, channels) \n",
    "# and y is a numpy array of corresponding labels. (In our case its train_generator)\n",
    "\n",
    "# def sample_weights(data):\n",
    "#     weights = []\n",
    "#     zero_sum = 0\n",
    "#     for data, _ in train_generator:\n",
    "#        batch_size = data.shape[0]\n",
    "#        for image_index in range(batch_size):\n",
    "#             image = data[image_index]\n",
    "#             summed_pixels = np.sum(image)\n",
    "#             if summed_pixels == 0:\n",
    "#                 weights.append(0)\n",
    "#                 zero_sum += 1\n",
    "#             else:\n",
    "#                 # try using sqrt transformation for weight skew\n",
    "#                 # weights.append(1 / np.sqrt(summed_pixels))\n",
    "#                 weights.append(1 / summed_pixels)\n",
    "#     train_generator.reset()\n",
    "#     median_weight = np.median(weights)\n",
    "#     weights = [median_weight if weight == 0 else weight for weight in weights]\n",
    "#     return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers \n",
    "from keras import models \n",
    "\n",
    "model = models.Sequential() \n",
    "\n",
    "# Conv Pool 1\n",
    "model.add(layers.Conv2D(4, (3, 3), input_shape=(240, 320, 1)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Conv Pool 2\n",
    "model.add(layers.Conv2D(8, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Conv Pool 3\n",
    "model.add(layers.Conv2D(8, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Conv Pool4\n",
    "model.add(layers.Conv2D(4, (3, 3)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.ReLU())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(2400, activation='relu')) \n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(32, activation='relu')) \n",
    "model.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization (Confusion Matrix and ROC Curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code from https://neptune.ai/blog/keras-metrics\n",
    "#to use to plot confusion matrix and roc curve after each epock\n",
    "#uncomment when you need it \n",
    "\n",
    "# import os\n",
    "\n",
    "# from keras.callbacks import Callback\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scikitplot.metrics import plot_confusion_matrix, plot_roc\n",
    "# class PerformanceVisualizationCallback(Callback):\n",
    "#     def __init__(self, model, validation_data, image_dir):\n",
    "#         super().__init__()\n",
    "#         self.model = model\n",
    "#         self.validation_data = validation_data\n",
    "\n",
    "#         os.makedirs(image_dir, exist_ok=True)\n",
    "#         self.image_dir = image_dir\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         y_pred = np.asarray(self.model.predict(self.validation_data[0]))\n",
    "#         y_true = self.validation_data[1]\n",
    "#         y_pred_class = np.argmax(y_pred, axis=1)\n",
    "\n",
    "#         # plot and save confusion matrix\n",
    "#         fig, ax = plt.subplots(figsize=(16,12))\n",
    "#         plot_confusion_matrix(y_true, y_pred_class, ax=ax)\n",
    "#         fig.savefig(os.path.join(self.image_dir, f'confusion_matrix_epoch_{epoch}'))\n",
    "\n",
    "#        # plot and save roc curve\n",
    "#         fig, ax = plt.subplots(figsize=(16,12))\n",
    "#         plot_roc(y_true, y_pred, ax=ax)\n",
    "#         fig.savefig(os.path.join(self.image_dir, f'roc_curve_epoch_{epoch}'))\n",
    "\n",
    "# performance_cbk = PerformanceVisualizationCallback(\n",
    "#                       model=model,\n",
    "#                       validation_data=val_generator,\n",
    "#                       image_dir='performance_vizualizations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers \n",
    "from keras import metrics\n",
    "\n",
    "def F1Score(y_true, y_pred):\n",
    "    prec = metrics.Precision()\n",
    "    recall = metrics.Recall()\n",
    "    prec.update_state(y_true, y_pred)\n",
    "    recall.update_state(y_true, y_pred)\n",
    "    prec_res = prec.result().numpy()\n",
    "    rec_res = recall.result().numpy()\n",
    "    return 2 * (prec_res * rec_res) / (prec_res + rec_res)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=1e-4), metrics=[F1Score, \"acc\"], run_eagerly=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 5\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=get_with_featurewise_center_std_norm(train_generator, mean, std),\n",
    "    steps_per_epoch= train_generator.samples // batch_size,\n",
    "    validation_data=get_with_featurewise_center_std_norm(val_generator, mean, std),\n",
    "    validation_steps = val_generator.samples // batch_size,\n",
    "    epochs = num_epochs,\n",
    "    class_weight=class_weight,\n",
    "    # callbacks=[performance_cbk] #uncomment once you want to use it\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Metrics Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "f1 = history.history['F1Score'] \n",
    "val_f1 = history.history['val_F1Score'] \n",
    "loss = history.history['loss'] \n",
    "val_loss = history.history['val_loss'] \n",
    "\n",
    "epochs = range(1, len(f1) + 1) \n",
    "\n",
    "plt.plot(epochs, f1, 'bo', label='Training F1 Score') \n",
    "plt.plot(epochs, val_f1, 'b', label='Validation F1 Score') \n",
    "plt.title('Training and Validation F1 Score') \n",
    "plt.legend() \n",
    "\n",
    "plt.figure() \n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
    "plt.plot(epochs, val_loss, 'b', label='Validaion loss') \n",
    "plt.title('Training loss and validation loss') \n",
    "plt.legend() \n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://stackoverflow.com/questions/45413712/keras-get-true-labels-y-test-from-imagedatagenerator-or-predict-generator\n",
    "\n",
    "# Create lists for storing the predictions and labels\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "threshold = 0.5\n",
    "# Get the total number of labels in generator \n",
    "# (i.e. the length of the dataset where the generator generates batches from)\n",
    "length_test = len(test_generator.labels)\n",
    "\n",
    "# Loop over the generator\n",
    "for data, label in test_generator:\n",
    "    # Make predictions on data using the model. Store the results.\n",
    "    preds = model.predict(data, verbose=0)\n",
    "    processed_preds = (preds >= threshold).flatten().astype(int)\n",
    "    predictions.extend(processed_preds)\n",
    "    # Store corresponding labels\n",
    "    labels.extend(label.astype(int))\n",
    "    \n",
    "    # We have to break out from the generator when we've processed \n",
    "    # the entire once (otherwise we would end up with duplicates). \n",
    "    if (len(label) < test_generator.batch_size) and (len(predictions) == length_test):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions), len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.sum([1 if predictions[i] == labels[i] else 0 for i in range(len(predictions))]) / length_test\n",
    "print(f'Test Accuracy is {test_acc} after training for {num_epochs} epochs on {length_test} test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leak_indices = [i for i in range(length_test) if labels[i] == train_generator.class_indices[\"Leak\"]] \n",
    "nonleak_indices = [i for i in range(length_test) if labels[i] == train_generator.class_indices[\"Nonleaks\"]]\n",
    "\n",
    "leak_predictions, leak_y_test = [predictions[i] for i in leak_indices], [labels[i] for i in leak_indices]\n",
    "nonleak_predictions, nonleak_y_test = [predictions[i] for i in nonleak_indices], [labels[i] for i in nonleak_indices]\n",
    "\n",
    "leak_test_acc = np.sum([1 if leak_predictions[i] == leak_y_test[i] else 0 for i in range(len(leak_y_test))]) / len(leak_y_test)\n",
    "nonleak_test_acc = np.sum([1 if nonleak_predictions[i] == nonleak_y_test[i] else 0 for i in range(len(nonleak_y_test))]) / len(nonleak_y_test)\n",
    "\n",
    "print(f'Leak Test accuracy is {leak_test_acc} after training for {num_epochs} epochs on {len(leak_y_test)} leak test images')\n",
    "print(f'Non-Leak Test accuracy is {nonleak_test_acc} after training for {num_epochs} epochs on {len(nonleak_y_test)} non-leak test images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Squishy-Methane-Analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
