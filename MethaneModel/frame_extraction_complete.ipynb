{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor, ViTConfig\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Average Background Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def calc_median(frames):\n",
    "    median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
    "    return median_frame\n",
    "\n",
    "def doMovingAverageBGS(image, prev_frames):\n",
    "    median_img = calc_median(prev_frames)\n",
    "    image = cv2.absdiff(image, median_img)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "\n",
    "# get paths to training and testing data\n",
    "data_dir = os.path.join(dir_path, 'data')\n",
    "train_data_dir = os.path.join(data_dir, 'train')\n",
    "test_data_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "# get path to folder where extracted frames are stored\n",
    "background_path = os.path.join(dir_path, 'background_sub_testing_movingavg2')\n",
    "os.makedirs(background_path, exist_ok=True)\n",
    "\n",
    "#path to where binary frames are stored\n",
    "frame_data_dir = os.path.join(dir_path, \"background_sub_movingavg_frames2\")\n",
    "frame_train_data_dir = os.path.join(frame_data_dir, 'train')\n",
    "frame_test_data_dir = os.path.join(frame_data_dir, 'test')\n",
    "\n",
    "frame_train_data_dir_nonleak = os.path.join(frame_train_data_dir, 'Nonleaks')\n",
    "frame_train_data_dir_leak = os.path.join(frame_train_data_dir, 'Leaks')\n",
    "frame_test_data_dir_nonleak = os.path.join(frame_test_data_dir, 'Nonleaks')\n",
    "frame_test_data_dir_leak = os.path.join(frame_test_data_dir, 'Leaks')\n",
    "\n",
    "os.makedirs(frame_data_dir, exist_ok=True)\n",
    "os.makedirs(frame_train_data_dir, exist_ok=True)\n",
    "os.makedirs(frame_test_data_dir, exist_ok=True)\n",
    "\n",
    "os.makedirs(frame_train_data_dir_nonleak, exist_ok=True)\n",
    "os.makedirs(frame_train_data_dir_leak, exist_ok=True)\n",
    "os.makedirs(frame_test_data_dir_nonleak, exist_ok=True)\n",
    "os.makedirs(frame_test_data_dir_leak, exist_ok=True)\n",
    "\n",
    "# get folder to put 8 classes in\n",
    "classes_folder = os.path.join(dir_path, 'background_sub_movingavg8_frames2')\n",
    "os.makedirs(classes_folder, exist_ok=True)\n",
    "\n",
    "classes_train_folder = os.path.join(classes_folder, 'train')\n",
    "os.makedirs(classes_train_folder, exist_ok = True)\n",
    "\n",
    "classes_test_folder = os.path.join(classes_folder, 'test')\n",
    "os.makedirs(classes_test_folder, exist_ok = True)\n",
    "\n",
    "for i in range(8):\n",
    "    os.makedirs(os.path.join(classes_train_folder, 'C' + str(i)), exist_ok=True)\n",
    "    os.makedirs(os.path.join(classes_test_folder, 'C' + str(i)), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(vid_path, out_path, med_count):\n",
    "\n",
    "    before_path = os.path.join(out_path, 'before')\n",
    "    after_path = os.path.join(out_path, 'after')\n",
    "    median_path = os.path.join(out_path, 'median')\n",
    "\n",
    "    print(\"Before path\" + before_path, flush = True)\n",
    "    print(\"After path\" + after_path, flush = True)\n",
    "    print(\"Median path\" + median_path, flush = True)\n",
    "\n",
    "    os.makedirs(before_path, exist_ok=True)\n",
    "    os.makedirs(after_path, exist_ok=True)\n",
    "    os.makedirs(median_path, exist_ok=True)\n",
    "\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, 0)\n",
    "    success = True\n",
    "\n",
    "    num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "    print(\"Num frames: %d\" % num_frames, flush = True)\n",
    "    print(\"Frames per second: %d\" % fps, flush = True)\n",
    "\n",
    "    prev_imgs = []\n",
    "    times = []\n",
    "\n",
    "    for i in range(med_count):\n",
    "        success, image = cap.read()\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        prev_imgs.append(image) \n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, 0)\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        success, image = cap.read()\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        time = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "        times.append(time)\n",
    "        cv2.imwrite(os.path.join(before_path, 'test%d.jpg' % i), image)\n",
    "        median_background = np.median(prev_imgs, axis = 0)\n",
    "        cv2.imwrite(os.path.join(median_path, 'test%d.jpg' % i), median_background)\n",
    "        removed_image = doMovingAverageBGS(image, prev_imgs)\n",
    "        cv2.imwrite(os.path.join(after_path, 'test%d.jpg' % i), removed_image)\n",
    "        prev_imgs.pop(0)\n",
    "        prev_imgs.append(image)\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    df_time = pd.DataFrame(times)\n",
    "    df_time.to_csv(out_path + '/df_time.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting vid_id: 2580\n",
      "Before path/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg2/2580/before\n",
      "After path/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg2/2580/after\n",
      "Median path/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg2/2580/median\n",
      "Num frames: 22095\n",
      "Frames per second: 14\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(train_data_dir):\n",
    "    vid_path = os.path.join(train_data_dir, file)\n",
    "    vid_id = int(re.findall(\"_(\\d{4}).mp4\",os.path.basename(vid_path))[0])\n",
    "    print(\"Extracting vid_id: %d\" % vid_id, flush = True)\n",
    "    output_path = os.path.join(background_path, str(vid_id))\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    get_frames(vid_path, output_path, 210)\n",
    "\n",
    "for file in os.listdir(test_data_dir):\n",
    "    vid_path = os.path.join(test_data_dir, file)\n",
    "    vid_id = int(re.findall(\"_(\\d{4}).mp4\",os.path.basename(vid_path))[0])\n",
    "    print(\"Extracting vid_id: %d\" % vid_id, flush = True)\n",
    "    output_path = os.path.join(background_path, str(vid_id))\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    get_frames(vid_path, output_path, 210)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving frames to binary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = pd.read_csv('/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/GasVid_Ranges_Seconds.csv')\n",
    "ranges = ranges.set_index('Video No.')\n",
    "ranges.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_frames_nonleak(vid_id, train_test_path):\n",
    "    col_names = [\"Index\", \"Times\"]\n",
    "    stat_times = pd.read_csv(os.path.join(background_path, '%d/df_time.csv' % vid_id), names = col_names, header = None)\n",
    "    stat_times = stat_times.dropna()\n",
    "\n",
    "    nonleak_start = ranges.loc[vid_id,'Nonleak Range Start (s)'] * 1000\n",
    "    nonleak_end = ranges.loc[vid_id,'Nonleak Range End (s)'] * 1000\n",
    "\n",
    "    start_bool = stat_times['Times'] >= nonleak_start\n",
    "    end_bool = stat_times['Times'] <= nonleak_end\n",
    "\n",
    "    valid_index = stat_times[start_bool & end_bool]\n",
    "    valid_index = valid_index.astype({'Index': 'int32'})\n",
    "\n",
    "    folder_before = '/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg/%d/after' %vid_id\n",
    "    valid_index['Before Filename'] = valid_index[\"Index\"].apply(lambda x: os.path.join(folder_before, 'test%d.jpg'%x))\n",
    "    valid_index['After Filename'] = valid_index[\"Index\"].apply(lambda x: os.path.join(train_test_path, 'vid%dtest%d.jpg'%(vid_id,x)))\n",
    "    for i in range(valid_index.shape[0]):\n",
    "        before = valid_index.iloc[i,]['Before Filename']\n",
    "        after = valid_index.iloc[i,]['After Filename']\n",
    "        shutil.copy(before, after)\n",
    "\n",
    "def copy_frames_leak(vid_id, train_test_path):\n",
    "    col_names = [\"Index\", \"Times\"]\n",
    "    stat_times = pd.read_csv('/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg/%d/df_time.csv' % vid_id, names = col_names, header = None)\n",
    "    stat_times = stat_times.dropna()\n",
    "\n",
    "    leak_start = ranges.loc[vid_id,'Leak Range Start (s)'] * 1000\n",
    "    leak_end = ranges.loc[vid_id,'Leak Range End (s)'] * 1000\n",
    "\n",
    "    start_bool = stat_times['Times'] >= leak_start\n",
    "    end_bool = stat_times['Times'] <= leak_end\n",
    "\n",
    "    valid_index = stat_times[start_bool & end_bool]\n",
    "    valid_index = valid_index.astype({'Index': 'int32'})\n",
    "\n",
    "    folder_before = '/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg/%d/after' %vid_id\n",
    "    valid_index['Before Filename'] = valid_index[\"Index\"].apply(lambda x: os.path.join(folder_before, 'test%d.jpg'%x))\n",
    "    valid_index['After Filename'] = valid_index[\"Index\"].apply(lambda x: os.path.join(train_test_path, 'vid%dtest%d.jpg'%(vid_id,x)))\n",
    "    for i in range(valid_index.shape[0]):\n",
    "        before = valid_index.iloc[i,]['Before Filename']\n",
    "        after = valid_index.iloc[i,]['After Filename']\n",
    "        shutil.copy(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin moving training data\n",
      "Moving vid_id: 2580\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg2/2580/df_time.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m     vid_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;124m).mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m,os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(vid_path))[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMoving vid_id: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m vid_id, flush \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mcopy_frames_nonleak\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvid_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_train_data_dir_nonleak\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     copy_frames_leak(vid_id, frame_train_data_dir_leak)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBegin moving testing data\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mcopy_frames_nonleak\u001b[0;34m(vid_id, train_test_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy_frames_nonleak\u001b[39m(vid_id, train_test_path):\n\u001b[1;32m      2\u001b[0m     col_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m     stat_times \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackground_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m/df_time.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvid_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     stat_times \u001b[38;5;241m=\u001b[39m stat_times\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      6\u001b[0m     nonleak_start \u001b[38;5;241m=\u001b[39m ranges\u001b[38;5;241m.\u001b[39mloc[vid_id,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNonleak Range Start (s)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1012\u001b[0m     dialect,\n\u001b[1;32m   1013\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/site-packages/pandas/io/parsers/readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg2/2580/df_time.csv'"
     ]
    }
   ],
   "source": [
    "print(\"Begin moving training data\", flush = True)\n",
    "for file in os.listdir(train_data_dir):\n",
    "    vid_path = os.path.join(train_data_dir, file)\n",
    "    vid_id = int(re.findall(\"_(\\d{4}).mp4\",os.path.basename(vid_path))[0])\n",
    "    print(\"Moving vid_id: %d\" % vid_id, flush = True)\n",
    "    copy_frames_nonleak(vid_id, frame_train_data_dir_nonleak)\n",
    "    copy_frames_leak(vid_id, frame_train_data_dir_leak)\n",
    "\n",
    "print(\"Begin moving testing data\", flush = True)\n",
    "for file in os.listdir(test_data_dir):\n",
    "    vid_path = os.path.join(test_data_dir, file)\n",
    "    vid_id = int(re.findall(\"_(\\d{4}).mp4\",os.path.basename(vid_path))[0])\n",
    "    print(\"Moving vid_id: %d\" % vid_id, flush = True)\n",
    "    copy_frames_nonleak(vid_id, frame_test_data_dir_nonleak)\n",
    "    copy_frames_leak(vid_id, frame_test_data_dir_leak)\n",
    "print(\"Completed\", flush = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving frames to 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C0(S)</th>\n",
       "      <th>C0(E)</th>\n",
       "      <th>C1(S)</th>\n",
       "      <th>C1(E)</th>\n",
       "      <th>C2(S)</th>\n",
       "      <th>C2(E)</th>\n",
       "      <th>C3(S)</th>\n",
       "      <th>C3(E)</th>\n",
       "      <th>C4(S)</th>\n",
       "      <th>C4(E)</th>\n",
       "      <th>C5(S)</th>\n",
       "      <th>C5(E)</th>\n",
       "      <th>C6(S)</th>\n",
       "      <th>C6(E)</th>\n",
       "      <th>C7(S)</th>\n",
       "      <th>C7(E)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2564</th>\n",
       "      <td>31</td>\n",
       "      <td>191</td>\n",
       "      <td>211</td>\n",
       "      <td>371</td>\n",
       "      <td>391</td>\n",
       "      <td>551</td>\n",
       "      <td>571</td>\n",
       "      <td>731</td>\n",
       "      <td>751</td>\n",
       "      <td>911</td>\n",
       "      <td>931</td>\n",
       "      <td>1091</td>\n",
       "      <td>1111</td>\n",
       "      <td>1271</td>\n",
       "      <td>1291</td>\n",
       "      <td>1451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>44</td>\n",
       "      <td>204</td>\n",
       "      <td>224</td>\n",
       "      <td>384</td>\n",
       "      <td>404</td>\n",
       "      <td>564</td>\n",
       "      <td>584</td>\n",
       "      <td>744</td>\n",
       "      <td>764</td>\n",
       "      <td>924</td>\n",
       "      <td>944</td>\n",
       "      <td>1104</td>\n",
       "      <td>1124</td>\n",
       "      <td>1284</td>\n",
       "      <td>1304</td>\n",
       "      <td>1464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2560</th>\n",
       "      <td>32</td>\n",
       "      <td>192</td>\n",
       "      <td>212</td>\n",
       "      <td>372</td>\n",
       "      <td>392</td>\n",
       "      <td>552</td>\n",
       "      <td>572</td>\n",
       "      <td>732</td>\n",
       "      <td>752</td>\n",
       "      <td>912</td>\n",
       "      <td>932</td>\n",
       "      <td>1092</td>\n",
       "      <td>1112</td>\n",
       "      <td>1272</td>\n",
       "      <td>1292</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2561</th>\n",
       "      <td>34</td>\n",
       "      <td>194</td>\n",
       "      <td>214</td>\n",
       "      <td>374</td>\n",
       "      <td>394</td>\n",
       "      <td>554</td>\n",
       "      <td>574</td>\n",
       "      <td>734</td>\n",
       "      <td>754</td>\n",
       "      <td>914</td>\n",
       "      <td>934</td>\n",
       "      <td>1094</td>\n",
       "      <td>1114</td>\n",
       "      <td>1274</td>\n",
       "      <td>1294</td>\n",
       "      <td>1454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2562</th>\n",
       "      <td>39</td>\n",
       "      <td>199</td>\n",
       "      <td>219</td>\n",
       "      <td>379</td>\n",
       "      <td>399</td>\n",
       "      <td>559</td>\n",
       "      <td>579</td>\n",
       "      <td>739</td>\n",
       "      <td>759</td>\n",
       "      <td>919</td>\n",
       "      <td>939</td>\n",
       "      <td>1099</td>\n",
       "      <td>1119</td>\n",
       "      <td>1279</td>\n",
       "      <td>1299</td>\n",
       "      <td>1459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           C0(S)  C0(E)  C1(S)  C1(E)  C2(S)  C2(E)  C3(S)  C3(E)  C4(S)  \\\n",
       "Video No.                                                                  \n",
       "2564          31    191    211    371    391    551    571    731    751   \n",
       "2559          44    204    224    384    404    564    584    744    764   \n",
       "2560          32    192    212    372    392    552    572    732    752   \n",
       "2561          34    194    214    374    394    554    574    734    754   \n",
       "2562          39    199    219    379    399    559    579    739    759   \n",
       "\n",
       "           C4(E)  C5(S)  C5(E)  C6(S)  C6(E)  C7(S)  C7(E)  \n",
       "Video No.                                                   \n",
       "2564         911    931   1091   1111   1271   1291   1451  \n",
       "2559         924    944   1104   1124   1284   1304   1464  \n",
       "2560         912    932   1092   1112   1272   1292   1452  \n",
       "2561         914    934   1094   1114   1274   1294   1454  \n",
       "2562         919    939   1099   1119   1279   1299   1459  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranges = pd.read_csv(\"/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/GasVid_Ranges_all.csv\", index_col = \"Video No.\")\n",
    "ranges.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_8_classes(vid_id, train_test_path):\n",
    "    col_names = [\"Index\", \"Times\"]\n",
    "    frame_times = pd.read_csv('/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg/%d/df_time.csv' % vid_id, names = col_names, header = None)\n",
    "    frame_times = frame_times.dropna()\n",
    "    folder_vid = '/home/bestlab/Desktop/Squishy-Methane-URAP-New/AngelineLee/MethaneModel/background_sub_testing_movingavg/%d/after' %vid_id\n",
    "\n",
    "    for i in range(8):\n",
    "        start_time = ranges.loc[vid_id, 'C%d(S)'%i] * 1000\n",
    "        end_time = ranges.loc[vid_id, 'C%d(E)'%i] * 1000\n",
    "\n",
    "        start_bool = frame_times['Times'] >= start_time\n",
    "        end_bool = frame_times['Times'] <= end_time\n",
    "        valid_index = frame_times[start_bool & end_bool]\n",
    "        valid_index = valid_index.astype({'Index': 'int32'})\n",
    "        \n",
    "        valid_index['Before Filename'] = valid_index[\"Index\"].apply(lambda x: os.path.join(folder_vid, 'test%d.jpg'%x))\n",
    "        class_folder = os.path.join(train_test_path, 'C' + str(i))\n",
    "        valid_index['After Filename'] = valid_index[\"Index\"].apply(lambda x: os.path.join(class_folder, 'vid%dtest%d.jpg'%(vid_id,x)))\n",
    "        for i in range(valid_index.shape[0]):\n",
    "            before = valid_index.iloc[i,]['Before Filename']\n",
    "            after = valid_index.iloc[i,]['After Filename']\n",
    "            shutil.copy(before, after)\n",
    "    print('Finished moving video %d'%vid_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving vid_id: 2580\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     extract_8_classes(vid_id, classes_test_folder)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mextract_8_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvid_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses_train_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[38], line 22\u001b[0m, in \u001b[0;36mextract_8_classes\u001b[0;34m(vid_id, train_test_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m         before \u001b[38;5;241m=\u001b[39m valid_index\u001b[38;5;241m.\u001b[39miloc[i,][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBefore Filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m         after \u001b[38;5;241m=\u001b[39m valid_index\u001b[38;5;241m.\u001b[39miloc[i,][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAfter Filename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbefore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mafter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished moving video \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mvid_id)\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/shutil.py:417\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    416\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 417\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/anaconda3/envs/angeline/lib/python3.10/shutil.py:233\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Copy data from src to dst in the most efficient way possible.\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03mIf follow_symlinks is not set and src is a symbolic link, a new\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03msymlink will be created instead of copying the file it points to.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \n\u001b[1;32m    230\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    231\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutil.copyfile\u001b[39m\u001b[38;5;124m\"\u001b[39m, src, dst)\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_samefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SameFileError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m are the same file\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(src, dst))\n\u001b[1;32m    236\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file in os.listdir(background_path):\n",
    "    vid_path = os.path.join(background_path, file)\n",
    "    vid_id = int(file)\n",
    "    print(\"Moving vid_id: %d\" % vid_id, flush = True)\n",
    "    if file[0] == '1':\n",
    "        extract_8_classes(vid_id, classes_test_folder)\n",
    "    if file[0] == '2':\n",
    "        extract_8_classes(vid_id, classes_train_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "angeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
