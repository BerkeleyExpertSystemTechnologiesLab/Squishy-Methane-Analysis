{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_-w0DYiVX7g"
      },
      "source": [
        "### This is a Pytorch version of the work, for easier time working with ViT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgTfcIPVX7l"
      },
      "source": [
        "# Step 1: Load and Preprocess the Dataset\n",
        "\n",
        "### Load the GasVid dataset\n",
        "### Preprocess the data\n",
        "### Split the dataset into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install --upgrade pip\n",
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if apple and want MPS acceleration do this\n",
        "# %%capture\n",
        "# %pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 10680,
          "status": "ok",
          "timestamp": 1696464635710,
          "user": {
            "displayName": "Angeline Lee",
            "userId": "12532490570362671000"
          },
          "user_tz": 420
        },
        "id": "JObjEqgBVX7n"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-11 23:53:42.621286: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-11 23:53:42.621317: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-11 23:53:42.621336: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-11 23:53:42.625798: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor, ViTConfig\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.metrics import RocCurveDisplay, roc_curve, ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P5AqjEqiVX7o"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def calc_median(frames):\n",
        "    median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
        "    return median_frame\n",
        "\n",
        "def doMovingAverageBGS(image, prev_frames):\n",
        "    median_img = calc_median(prev_frames)\n",
        "    image = cv2.absdiff(image, median_img)\n",
        "    return image\n",
        "\n",
        "def calc_avg(frames):\n",
        "  average_frame = np.mean(frames).astype(dtype=np.uint8)\n",
        "  return average_frame\n",
        "\n",
        "# Try Fixed background substraction\n",
        "def doFixedBGS(image, init_frames):\n",
        "  init_img = calc_avg(init_frames)\n",
        "  image = cv2.absdiff(image, init_img)\n",
        "  return image\n",
        "\n",
        "# Try Mixture of Gaussian-Based (MOG) background substraction\n",
        "def doMOGBGS(image, all_frames):\n",
        "  gmm = GaussianMixture(n_components = 2)\n",
        "  gmm_background = np.zeros(shape=(all_frames.shape[1:]))\n",
        "  for i in range(all_frames.shape[1]):\n",
        "      for j in range(all_frames.shape[2]):\n",
        "          for k in range(all_frames.shape[3]):\n",
        "              X = all_frames[:, i, j, k]\n",
        "              X = X.reshape(X.shape[0], 1)\n",
        "              gmm.fit(X)\n",
        "              means = gmm.means_\n",
        "              covars = gmm.covariances_\n",
        "              weights = gmm.weights_\n",
        "              idx = np.argmax(weights)\n",
        "              gmm_background[i][j][k] = int(means[idx])\n",
        "  image = cv2.absdiff(image, gmm_background)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EuSupi3EVX7o"
      },
      "outputs": [],
      "source": [
        "def extractImages(pathIn, pathOut, leakRange, nonleakRange, currCountLeak, currCountNonLeak):\n",
        "\n",
        "  '''\n",
        "  Input:\n",
        "    String: pathIn should be the path of the video\n",
        "    String: pathOut should be the path of the folder where data is being stored for testing or training\n",
        "    Tuple: range of leak frames from video\n",
        "    Tuple: range of nonleak frames from video\n",
        "\n",
        "  Output:\n",
        "    creates two subfolders in pathOut called Leaks and Nonleaks\n",
        "      Leaks folder contains the frames where there are leaks\n",
        "      Nonleaks folder contains the frames where there are noleaks\n",
        "  '''\n",
        "\n",
        "  leakPath = os.path.join(pathOut, \"Leak\")\n",
        "  nonleakPath = os.path.join(pathOut, \"Nonleaks\")\n",
        "\n",
        "  os.makedirs(leakPath, exist_ok=True)\n",
        "  os.makedirs(nonleakPath, exist_ok=True)\n",
        "\n",
        "  def helper(pathIn, pathOut, range, isLeak, currCountLeak, currCountNonLeak):\n",
        "    '''\n",
        "    Might need to clean this up, but this was extracted from the original extractImages from the previous implementation\n",
        "\n",
        "    '''\n",
        "    #setting up moving average list\n",
        "    prev_imgs = []\n",
        "    prev_limit = 210 #210 in paper\n",
        "\n",
        "    start = range[0] * 1000 # converting seconds to milliseconds\n",
        "    end = range[1] * 1000\n",
        "    cap = cv2.VideoCapture(pathIn)\n",
        "    cap.set(cv2.CAP_PROP_POS_MSEC, start)\n",
        "    success = True\n",
        "\n",
        "    if cap.isOpened():\n",
        "      while success and start < end:\n",
        "          success, image = cap.read()\n",
        "          if success:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            start = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "            prev_imgs.append(image)\n",
        "            if len(prev_imgs) > prev_limit:\n",
        "                prev_imgs.pop(0)\n",
        "\n",
        "            processed_img = doMovingAverageBGS(image, prev_imgs) #to generalize might need to make this function as a parameter\n",
        "\n",
        "            if isLeak:\n",
        "                cv2.imwrite(os.path.join(pathOut, \"leak.frame%d.jpg\" % currCountLeak), processed_img)     # save frame as JPEG file\n",
        "                currCountLeak += 1\n",
        "            else:\n",
        "                cv2.imwrite(os.path.join(pathOut, \"nonleak.frame%d.jpg\" % currCountNonLeak), processed_img)\n",
        "                currCountNonLeak += 1\n",
        "          else:\n",
        "            break\n",
        "      cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    if isLeak:\n",
        "       return currCountLeak\n",
        "    else:\n",
        "       return currCountNonLeak\n",
        "  # call helper for both nonLeak and leak and get updated counts\n",
        "  updated_currCountNonLeak = helper(pathIn, nonleakPath, nonleakRange, isLeak=False, currCountLeak=currCountLeak, currCountNonLeak=currCountNonLeak)\n",
        "  updated_currCountLeak = helper(pathIn, leakPath, leakRange, isLeak=True,currCountLeak=currCountLeak, currCountNonLeak=currCountNonLeak)\n",
        "\n",
        "  return updated_currCountNonLeak, updated_currCountLeak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rMPE8CVX7p"
      },
      "source": [
        "### Setting up Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xA87iKePVX7p"
      },
      "outputs": [],
      "source": [
        "# get generic path to directory\n",
        "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
        "\n",
        "# get all raw video data directories\n",
        "data_dir = os.path.join(dir_path, 'data')\n",
        "\n",
        "train_data_dir = os.path.join(data_dir, 'train')\n",
        "test_data_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "frame_data_dir = os.path.join(dir_path, 'frame_data_movingAvg')\n",
        "frame_train_data_dir = os.path.join(frame_data_dir, 'train')\n",
        "frame_test_data_dir = os.path.join(frame_data_dir, 'test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55RvfvVKVX7q"
      },
      "source": [
        "### Setting Up Ranges for Each Video In GasVid (Excluding 18.6m and 8.8m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 160,
          "status": "ok",
          "timestamp": 1695939634949,
          "user": {
            "displayName": "Zhuoyi Jin",
            "userId": "15256655862188224441"
          },
          "user_tz": 420
        },
        "id": "Rk9e28D5VX7q",
        "outputId": "62923369-9bf7-4dd2-ef9d-4723dd611916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data = np.loadtxt(os.path.join(dir_path, 'GasVid_Ranges_Seconds.csv'), skiprows=1, delimiter=',', dtype=int)\n",
        "\n",
        "ranges = list(zip(raw_data[:, 0], raw_data[:, 1:3], raw_data[:, 3:5])) #need to upload new ranges\n",
        "ranges = {ranges[i][0] : (ranges[i][1], ranges[i][2]) for i in range(len(ranges))}\n",
        "len(ranges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rzKc3Im2VX7q"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def read_frames_from_dir(dir_path, output_path, max_vids=None):\n",
        "    cur_count = 1\n",
        "    currNonLeakCount = 0\n",
        "    currLeakCount = 0\n",
        "\n",
        "    for file in os.listdir(dir_path):\n",
        "        if max_vids and cur_count > max_vids:\n",
        "            break\n",
        "        vid_path = os.path.join(dir_path, file)\n",
        "        vid_id = int(re.findall(\"_(\\d{4}).mp4\",os.path.basename(vid_path))[0])\n",
        "        # vid_id = int(os.path.basename(vid_path)[4:8])\n",
        "        if vid_id not in ranges.keys():\n",
        "            continue\n",
        "\n",
        "        nonleak_start = ranges[vid_id][0][0]\n",
        "        nonleak_end = ranges[vid_id][0][1]\n",
        "        leak_start = ranges[vid_id][1][0]\n",
        "        leak_end = ranges[vid_id][1][1]\n",
        "\n",
        "        currNonLeakCount, currLeakCount = extractImages(vid_path, output_path, (leak_start, leak_end), (nonleak_start, nonleak_end), currLeakCount, currNonLeakCount)\n",
        "        print(\"Video\", vid_id)\n",
        "        print(\"Current NonLeak Count\", currNonLeakCount)\n",
        "        print(\"Current Leak Count\", currLeakCount)\n",
        "\n",
        "        print('Done with', cur_count, \"video(s)\")\n",
        "        cur_count += 1\n",
        "    return currNonLeakCount, currLeakCount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwswcfKsVX7q"
      },
      "source": [
        "### Reading Frames from Data Directory and Setting Them in Frame Data Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "executionInfo": {
          "elapsed": 3260,
          "status": "error",
          "timestamp": 1695935836295,
          "user": {
            "displayName": "Zhuoyi Jin",
            "userId": "15256655862188224441"
          },
          "user_tz": 420
        },
        "id": "pMjN0VGOVX7r",
        "outputId": "e9870ba2-25a9-4766-ec11-bc89f4b32be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video 2570\n",
            "Current NonLeak Count 2386\n",
            "Current Leak Count 18475\n",
            "Done with 1 video(s)\n",
            "Video 2564\n",
            "Current NonLeak Count 4774\n",
            "Current Leak Count 36946\n",
            "Done with 2 video(s)\n",
            "Video 2559\n",
            "Current NonLeak Count 7160\n",
            "Current Leak Count 55410\n",
            "Done with 3 video(s)\n",
            "Video 2567\n",
            "Current NonLeak Count 9545\n",
            "Current Leak Count 73896\n",
            "Done with 4 video(s)\n",
            "Done with Training Data\n",
            "Video 1469\n",
            "Current NonLeak Count 2384\n",
            "Current Leak Count 18485\n",
            "Done with 1 video(s)\n",
            "Video 1468\n",
            "Current NonLeak Count 4771\n",
            "Current Leak Count 36972\n",
            "Done with 2 video(s)\n",
            "Done with Testing Data\n"
          ]
        }
      ],
      "source": [
        "image_dim = (240, 320)\n",
        "vid_count = None # Smaller on local computer to limit computer resources #max =>15\n",
        "\n",
        "test_count = None #Smaller on local computer to limit computer resources #max =>10\n",
        "total_train_NonLeak, total_train_Leak = read_frames_from_dir(train_data_dir, frame_train_data_dir, vid_count)\n",
        "print(\"Done with Training Data\")\n",
        "total_test_NonLeak, total_test_Leak = read_frames_from_dir(test_data_dir, frame_test_data_dir, test_count)\n",
        "print(\"Done with Testing Data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8oyYtwX4VX7r"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'total_train_NonLeak' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/Gas-ViT.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbestlab/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/Gas-ViT.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal NonLeak Count\u001b[39m\u001b[39m\"\u001b[39m, total_train_NonLeak \u001b[39m+\u001b[39m total_test_NonLeak)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbestlab/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/Gas-ViT.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal Leak Count\u001b[39m\u001b[39m\"\u001b[39m, total_train_Leak \u001b[39m+\u001b[39m total_test_Leak)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'total_train_NonLeak' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Total NonLeak Count\", total_train_NonLeak + total_test_NonLeak)\n",
        "print(\"Total Leak Count\", total_train_Leak + total_test_Leak)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2: Create Dataset for Ingesting Image Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiClassVideoFrameDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, processor=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.processor = processor\n",
        "        self.classes = os.listdir(root_dir)  # Get class names from subdirectories\n",
        "\n",
        "        self.frames = []\n",
        "        self.labels = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_dir = os.path.join(self.root_dir, class_name)\n",
        "            frame_list = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "            self.frames.extend(frame_list)\n",
        "            self.labels.extend([class_idx] * len(frame_list))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_path = self.frames[idx]\n",
        "        image = cv2.imread(frame_path)\n",
        "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        if self.processor:\n",
        "            image = self.processor.preprocess(image, return_tensors=\"pt\")\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_processor = ViTImageProcessor(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    do_normalize=True,\n",
        "    max_size=384,\n",
        "    pad_to_max_size=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define some transforms\n",
        "transform = transforms.Compose([\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_train_dataset = MultiClassVideoFrameDataset(root_dir=frame_train_data_dir, transform=transform, processor=image_processor)\n",
        "test_dataset = MultiClassVideoFrameDataset(root_dir=frame_test_data_dir, transform=transform, processor=image_processor)\n",
        "\n",
        "# Define the percentage of data to use for validation\n",
        "validation_split = 0.2  # Adjust this as needed\n",
        "\n",
        "# Calculate the number of samples for the validation set\n",
        "num_samples = len(full_train_dataset)\n",
        "num_val_samples = int(validation_split * num_samples)\n",
        "num_train_samples = num_samples - num_val_samples\n",
        "\n",
        "# Create a list of indices for the full dataset\n",
        "indices = list(range(num_samples))\n",
        "\n",
        "# Use random sampling to split the indices into train and validation indices\n",
        "val_indices = torch.randperm(num_samples)[:num_val_samples]\n",
        "train_indices = list(set(indices) - set(val_indices))\n",
        "\n",
        "# Create Subset objects for train and validation\n",
        "train_dataset = Subset(full_train_dataset, train_indices)\n",
        "val_dataset = Subset(full_train_dataset, val_indices)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "584636"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(full_train_dataset) + len(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RAi_buLVX7r"
      },
      "source": [
        "# Step 3: Build the GasViT Architecture\n",
        "\n",
        "### Define the GasNet architecture (GasNet-2 as mentioned in the paper)\n",
        "### Implement the model using TensorFlow/Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "configs = ViTConfig(\n",
        "    hidden_dropout_prob=0.5,\n",
        "    attention_probs_dropout_prob=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.5, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.2, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.5, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.5, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the ViT feature extractor and model\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224', config=configs, ignore_mismatched_sizes=True)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=2, bias=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change classifier layer to have num classes consistent with dataset\n",
        "model.classifier.out_features = len(full_train_dataset.classes)\n",
        "model.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Leak', 'Nonleaks']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataloader.dataset.dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, weight=None, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss(weight=weight) # extendable for multiclass classification as well\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # can try out lr scheduler later if needed\n",
        "    # can also try out warmup ratio\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_images, batch_labels in tqdm(train_dataloader):\n",
        "            batch_image_pixels, batch_labels = batch_images.pixel_values.squeeze(1).to(device), batch_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_image_pixels).logits\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        accuracy = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_images, batch_labels in tqdm(val_dataloader, leave=False):\n",
        "                batch_image_pixels, batch_labels = batch_images.pixel_values.squeeze(1).to(device), batch_labels.to(device)\n",
        "                outputs = model(batch_image_pixels).logits\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                accuracy += (predicted == batch_labels).sum().item()\n",
        "                total_samples += batch_labels.size(0)\n",
        "\n",
        "        validation_accuracy = accuracy / total_samples\n",
        "        print(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adjust classweights to account for class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adjust Class weights here\n",
        "class_weight = torch.tensor([1, 8]).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ac98fb67de54b15a0f3cf3bc224dc04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6, Loss: 0.5135\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "369f0015aed24a3ea40f9c8e185c3e2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9210\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f71c77123e544ea8cb508205e30efdd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/6, Loss: 0.2012\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28549bdce33a473ca3ee7c2a98042104",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9443\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a79a5b0ed34744b9a396f1a7a19cb889",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/6, Loss: 0.1108\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a52f4a5fcfe487db8b82101ddcea994",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9442\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a92de8ebd5be4429ab2c3d6c76bcd19c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/6, Loss: 0.3122\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1587580fef0490e86942897bd76fd62",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9147\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a75f54d4981a473482cd6fca6697467e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/6, Loss: 0.0904\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c816eb5dbe5144f9bf1e95d379c4819d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9465\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68d1a137757f44acbc451180361b0651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/6, Loss: 0.1218\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70923f58bc6549b884b6b0046dbeb15c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9504\n"
          ]
        }
      ],
      "source": [
        "train(model, class_weight, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the file path for saving the model\n",
        "model_path = 'vit_model_dropout_weighted.pth'\n",
        "\n",
        "# Save the model's state_dict to the specified file\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = 'vit_model_dropout_weighted.pth'\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jddooPmpVX7t"
      },
      "source": [
        "# Step 4: Evaluate the model on the Test Dataset\n",
        "\n",
        "### Generate evaluation metrics and plots such as confusion matrix and ROC curves, F1 score, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v4ikO-tVX7t"
      },
      "source": [
        "We are primarily concerned with high false positive rate due to the extreme class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model):\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    total_samples = 0\n",
        "    predictions = []  # List to store the predictions\n",
        "    truth_labels = []  # List to store the truth labels\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_images, batch_labels in tqdm(test_dataloader, leave=False):\n",
        "            batch_image_pixels, batch_labels = batch_images.pixel_values.squeeze(1).to(device), batch_labels.to(device)\n",
        "            outputs = model(batch_image_pixels).logits\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            accuracy += (predicted == batch_labels).sum().item()\n",
        "            total_samples += batch_labels.size(0)\n",
        "\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            truth_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "    validation_accuracy = accuracy / total_samples\n",
        "    print(f\"Test Accuracy: {validation_accuracy:.4f}\")\n",
        "    return predictions, truth_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "328efae44ea94d6598b5f2f49a03fe51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/7402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8605\n"
          ]
        }
      ],
      "source": [
        "predictions, truth_labels = predict(model)\n",
        "predictions, truth_labels = np.array(predictions), np.array(truth_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "#source: https://vitalflux.com/python-draw-confusion-matrix-matplotlib/\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true=truth_labels.astype(int), y_pred=predictions)\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title(f'Confusion Matrix (0: Leak, 1:Nonleak)', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "accuracy = accuracy_score(truth_labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8605211825405538"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6260005207802648"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1 = f1_score(truth_labels, predictions)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(truth_labels, predictions)\n",
        "per_class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'Leak' Accuracy: 0.8451\n",
            "Class 'Nonleak' Accuracy: 0.9735\n"
          ]
        }
      ],
      "source": [
        "for label, acc in zip(['Leak', 'Nonleak'], per_class_accuracy)\n",
        "    print(f\"Class '{label}' Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCvUK3ryVX7t"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "methane_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "92148a12c102ce31dad7b6dc4c1f8747c19091aa07dd8a934fcd2c33582f9a61"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
