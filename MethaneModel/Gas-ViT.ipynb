{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_-w0DYiVX7g"
      },
      "source": [
        "### This is a Pytorch version of the work, for easier time working with ViT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSgTfcIPVX7l"
      },
      "source": [
        "# Step 1: Load and Preprocess the Dataset\n",
        "\n",
        "### Load the GasVid dataset\n",
        "### Preprocess the data\n",
        "### Split the dataset into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install --upgrade pip\n",
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if apple and want MPS acceleration do this\n",
        "# %%capture\n",
        "# %pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "executionInfo": {
          "elapsed": 10680,
          "status": "ok",
          "timestamp": 1696464635710,
          "user": {
            "displayName": "Angeline Lee",
            "userId": "12532490570362671000"
          },
          "user_tz": 420
        },
        "id": "JObjEqgBVX7n"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-11 14:31:19.519533: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-11 14:31:19.519561: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-11 14:31:19.519575: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-11 14:31:19.523397: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.metrics import RocCurveDisplay, roc_curve, ConfusionMatrixDisplay, confusion_matrix\n",
        "\n",
        "from sklearn.mixture import GaussianMixture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P5AqjEqiVX7o"
      },
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def calc_median(frames):\n",
        "    median_frame = np.median(frames, axis=0).astype(dtype=np.uint8)\n",
        "    return median_frame\n",
        "\n",
        "def doMovingAverageBGS(image, prev_frames):\n",
        "    median_img = calc_median(prev_frames)\n",
        "    image = cv2.absdiff(image, median_img)\n",
        "    return image\n",
        "\n",
        "def calc_avg(frames):\n",
        "  average_frame = np.mean(frames).astype(dtype=np.uint8)\n",
        "  return average_frame\n",
        "\n",
        "# Try Fixed background substraction\n",
        "def doFixedBGS(image, init_frames):\n",
        "  init_img = calc_avg(init_frames)\n",
        "  image = cv2.absdiff(image, init_img)\n",
        "  return image\n",
        "\n",
        "# Try Mixture of Gaussian-Based (MOG) background substraction\n",
        "def doMOGBGS(image, all_frames):\n",
        "  gmm = GaussianMixture(n_components = 2)\n",
        "  gmm_background = np.zeros(shape=(all_frames.shape[1:]))\n",
        "  for i in range(all_frames.shape[1]):\n",
        "      for j in range(all_frames.shape[2]):\n",
        "          for k in range(all_frames.shape[3]):\n",
        "              X = all_frames[:, i, j, k]\n",
        "              X = X.reshape(X.shape[0], 1)\n",
        "              gmm.fit(X)\n",
        "              means = gmm.means_\n",
        "              covars = gmm.covariances_\n",
        "              weights = gmm.weights_\n",
        "              idx = np.argmax(weights)\n",
        "              gmm_background[i][j][k] = int(means[idx])\n",
        "  image = cv2.absdiff(image, gmm_background)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EuSupi3EVX7o"
      },
      "outputs": [],
      "source": [
        "def extractImages(pathIn, pathOut, leakRange, nonleakRange, currCountLeak, currCountNonLeak):\n",
        "\n",
        "  '''\n",
        "  Input:\n",
        "    String: pathIn should be the path of the video\n",
        "    String: pathOut should be the path of the folder where data is being stored for testing or training\n",
        "    Tuple: range of leak frames from video\n",
        "    Tuple: range of nonleak frames from video\n",
        "\n",
        "  Output:\n",
        "    creates two subfolders in pathOut called Leaks and Nonleaks\n",
        "      Leaks folder contains the frames where there are leaks\n",
        "      Nonleaks folder contains the frames where there are noleaks\n",
        "  '''\n",
        "\n",
        "  leakPath = os.path.join(pathOut, \"Leak\")\n",
        "  nonleakPath = os.path.join(pathOut, \"Nonleaks\")\n",
        "\n",
        "  os.makedirs(leakPath, exist_ok=True)\n",
        "  os.makedirs(nonleakPath, exist_ok=True)\n",
        "\n",
        "  def helper(pathIn, pathOut, range, isLeak, currCountLeak, currCountNonLeak):\n",
        "    '''\n",
        "    Might need to clean this up, but this was extracted from the original extractImages from the previous implementation\n",
        "\n",
        "    '''\n",
        "    #setting up moving average list\n",
        "    prev_imgs = []\n",
        "    prev_limit = 210 #210 in paper\n",
        "\n",
        "    start = range[0] * 1000 # converting seconds to milliseconds\n",
        "    end = range[1] * 1000\n",
        "    cap = cv2.VideoCapture(pathIn)\n",
        "    cap.set(cv2.CAP_PROP_POS_MSEC, start)\n",
        "    success = True\n",
        "\n",
        "    if cap.isOpened():\n",
        "      while success and start < end:\n",
        "          success, image = cap.read()\n",
        "          if success:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            start = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
        "            prev_imgs.append(image)\n",
        "            if len(prev_imgs) > prev_limit:\n",
        "                prev_imgs.pop(0)\n",
        "\n",
        "            processed_img = doMovingAverageBGS(image, prev_imgs) #to generalize might need to make this function as a parameter\n",
        "\n",
        "            if isLeak:\n",
        "                cv2.imwrite(os.path.join(pathOut, \"leak.frame%d.jpg\" % currCountLeak), processed_img)     # save frame as JPEG file\n",
        "                currCountLeak += 1\n",
        "            else:\n",
        "                cv2.imwrite(os.path.join(pathOut, \"nonleak.frame%d.jpg\" % currCountNonLeak), processed_img)\n",
        "                currCountNonLeak += 1\n",
        "          else:\n",
        "            break\n",
        "      cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    if isLeak:\n",
        "       return currCountLeak\n",
        "    else:\n",
        "       return currCountNonLeak\n",
        "  # call helper for both nonLeak and leak and get updated counts\n",
        "  updated_currCountNonLeak = helper(pathIn, nonleakPath, nonleakRange, isLeak=False, currCountLeak=currCountLeak, currCountNonLeak=currCountNonLeak)\n",
        "  updated_currCountLeak = helper(pathIn, leakPath, leakRange, isLeak=True,currCountLeak=currCountLeak, currCountNonLeak=currCountNonLeak)\n",
        "\n",
        "  return updated_currCountNonLeak, updated_currCountLeak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-rMPE8CVX7p"
      },
      "source": [
        "### Setting up Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xA87iKePVX7p"
      },
      "outputs": [],
      "source": [
        "# get generic path to directory\n",
        "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
        "\n",
        "# get all raw video data directories\n",
        "data_dir = os.path.join(dir_path, 'data')\n",
        "\n",
        "train_data_dir = os.path.join(data_dir, 'train')\n",
        "test_data_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "frame_data_dir = os.path.join(dir_path, 'frame_data_movingAvg')\n",
        "frame_train_data_dir = os.path.join(frame_data_dir, 'train')\n",
        "frame_test_data_dir = os.path.join(frame_data_dir, 'test')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55RvfvVKVX7q"
      },
      "source": [
        "### Setting Up Ranges for Each Video In GasVid (Excluding 18.6m and 8.8m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 160,
          "status": "ok",
          "timestamp": 1695939634949,
          "user": {
            "displayName": "Zhuoyi Jin",
            "userId": "15256655862188224441"
          },
          "user_tz": 420
        },
        "id": "Rk9e28D5VX7q",
        "outputId": "62923369-9bf7-4dd2-ef9d-4723dd611916"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_data = np.loadtxt(os.path.join(dir_path, 'GasVid_Ranges_Seconds.csv'), skiprows=1, delimiter=',', dtype=int)\n",
        "\n",
        "ranges = list(zip(raw_data[:, 0], raw_data[:, 1:3], raw_data[:, 3:5])) #need to upload new ranges\n",
        "ranges = {ranges[i][0] : (ranges[i][1], ranges[i][2]) for i in range(len(ranges))}\n",
        "len(ranges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rzKc3Im2VX7q"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def read_frames_from_dir(dir_path, output_path, max_vids=None):\n",
        "    cur_count = 1\n",
        "    currNonLeakCount = 0\n",
        "    currLeakCount = 0\n",
        "\n",
        "    for file in os.listdir(dir_path):\n",
        "        if max_vids and cur_count > max_vids:\n",
        "            break\n",
        "        vid_path = os.path.join(dir_path, file)\n",
        "        vid_id = int(re.findall(\"_(\\d{4}).mp4\",os.path.basename(vid_path))[0])\n",
        "        # vid_id = int(os.path.basename(vid_path)[4:8])\n",
        "        if vid_id not in ranges.keys():\n",
        "            continue\n",
        "\n",
        "        nonleak_start = ranges[vid_id][0][0]\n",
        "        nonleak_end = ranges[vid_id][0][1]\n",
        "        leak_start = ranges[vid_id][1][0]\n",
        "        leak_end = ranges[vid_id][1][1]\n",
        "\n",
        "        currNonLeakCount, currLeakCount = extractImages(vid_path, output_path, (leak_start, leak_end), (nonleak_start, nonleak_end), currLeakCount, currNonLeakCount)\n",
        "        print(\"Video\", vid_id)\n",
        "        print(\"Current NonLeak Count\", currNonLeakCount)\n",
        "        print(\"Current Leak Count\", currLeakCount)\n",
        "\n",
        "        print('Done with', cur_count, \"video(s)\")\n",
        "        cur_count += 1\n",
        "    return currNonLeakCount, currLeakCount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwswcfKsVX7q"
      },
      "source": [
        "### Reading Frames from Data Directory and Setting Them in Frame Data Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "executionInfo": {
          "elapsed": 3260,
          "status": "error",
          "timestamp": 1695935836295,
          "user": {
            "displayName": "Zhuoyi Jin",
            "userId": "15256655862188224441"
          },
          "user_tz": 420
        },
        "id": "pMjN0VGOVX7r",
        "outputId": "e9870ba2-25a9-4766-ec11-bc89f4b32be0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video 2570\n",
            "Current NonLeak Count 2386\n",
            "Current Leak Count 18475\n",
            "Done with 1 video(s)\n",
            "Video 2564\n",
            "Current NonLeak Count 4774\n",
            "Current Leak Count 36946\n",
            "Done with 2 video(s)\n",
            "Video 2559\n",
            "Current NonLeak Count 7160\n",
            "Current Leak Count 55410\n",
            "Done with 3 video(s)\n",
            "Video 2567\n",
            "Current NonLeak Count 9545\n",
            "Current Leak Count 73896\n",
            "Done with 4 video(s)\n",
            "Done with Training Data\n",
            "Video 1469\n",
            "Current NonLeak Count 2384\n",
            "Current Leak Count 18485\n",
            "Done with 1 video(s)\n",
            "Video 1468\n",
            "Current NonLeak Count 4771\n",
            "Current Leak Count 36972\n",
            "Done with 2 video(s)\n",
            "Done with Testing Data\n"
          ]
        }
      ],
      "source": [
        "image_dim = (240, 320)\n",
        "vid_count = None # Smaller on local computer to limit computer resources #max =>15\n",
        "\n",
        "test_count = None #Smaller on local computer to limit computer resources #max =>10\n",
        "total_train_NonLeak, total_train_Leak = read_frames_from_dir(train_data_dir, frame_train_data_dir, vid_count)\n",
        "print(\"Done with Training Data\")\n",
        "total_test_NonLeak, total_test_Leak = read_frames_from_dir(test_data_dir, frame_test_data_dir, test_count)\n",
        "print(\"Done with Testing Data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8oyYtwX4VX7r"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'total_train_NonLeak' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/Gas-ViT.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbestlab/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/Gas-ViT.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal NonLeak Count\u001b[39m\u001b[39m\"\u001b[39m, total_train_NonLeak \u001b[39m+\u001b[39m total_test_NonLeak)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bbestlab/home/bestlab/Desktop/Squishy-Methane-Analysis/MethaneModel/Gas-ViT.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal Leak Count\u001b[39m\u001b[39m\"\u001b[39m, total_train_Leak \u001b[39m+\u001b[39m total_test_Leak)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'total_train_NonLeak' is not defined"
          ]
        }
      ],
      "source": [
        "print(\"Total NonLeak Count\", total_train_NonLeak + total_test_NonLeak)\n",
        "print(\"Total Leak Count\", total_train_Leak + total_test_Leak)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Step 2: Create Dataset for Ingesting Image Frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiClassVideoFrameDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, processor=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.processor = processor\n",
        "        self.classes = os.listdir(root_dir)  # Get class names from subdirectories\n",
        "\n",
        "        self.frames = []\n",
        "        self.labels = []\n",
        "\n",
        "        for class_idx, class_name in enumerate(self.classes):\n",
        "            class_dir = os.path.join(self.root_dir, class_name)\n",
        "            frame_list = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.jpg', '.png', '.jpeg'))]\n",
        "            self.frames.extend(frame_list)\n",
        "            self.labels.extend([class_idx] * len(frame_list))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_path = self.frames[idx]\n",
        "        image = cv2.imread(frame_path)\n",
        "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        if self.processor:\n",
        "            image = self.processor.preprocess(image, return_tensors=\"pt\")\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_processor = ViTImageProcessor(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    do_normalize=True,\n",
        "    max_size=384,\n",
        "    pad_to_max_size=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# define some transforms\n",
        "transform = transforms.Compose([\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_train_dataset = MultiClassVideoFrameDataset(root_dir=frame_train_data_dir, transform=transform, processor=image_processor)\n",
        "test_dataset = MultiClassVideoFrameDataset(root_dir=frame_test_data_dir, transform=transform, processor=image_processor)\n",
        "\n",
        "# Define the percentage of data to use for validation\n",
        "validation_split = 0.2  # Adjust this as needed\n",
        "\n",
        "# Calculate the number of samples for the validation set\n",
        "num_samples = len(full_train_dataset)\n",
        "num_val_samples = int(validation_split * num_samples)\n",
        "num_train_samples = num_samples - num_val_samples\n",
        "\n",
        "# Create a list of indices for the full dataset\n",
        "indices = list(range(num_samples))\n",
        "\n",
        "# Use random sampling to split the indices into train and validation indices\n",
        "val_indices = torch.randperm(num_samples)[:num_val_samples]\n",
        "train_indices = list(set(indices) - set(val_indices))\n",
        "\n",
        "# Create Subset objects for train and validation\n",
        "train_dataset = Subset(full_train_dataset, train_indices)\n",
        "val_dataset = Subset(train_dataset, val_indices)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "test_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "584636"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(full_train_dataset) + len(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RAi_buLVX7r"
      },
      "source": [
        "# Step 3: Build the GasViT Architecture\n",
        "\n",
        "### Define the GasNet architecture (GasNet-2 as mentioned in the paper)\n",
        "### Implement the model using TensorFlow/Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device\n",
        "# model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ViTForImageClassification(\n",
              "  (vit): ViTModel(\n",
              "    (embeddings): ViTEmbeddings(\n",
              "      (patch_embeddings): ViTPatchEmbeddings(\n",
              "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
              "      )\n",
              "      (dropout): Dropout(p=0.0, inplace=False)\n",
              "    )\n",
              "    (encoder): ViTEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x ViTLayer(\n",
              "          (attention): ViTAttention(\n",
              "            (attention): ViTSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "            (output): ViTSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ViTIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ViTOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the ViT feature extractor and model\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear(in_features=768, out_features=2, bias=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change classifier layer to have num classes consistent with dataset\n",
        "model.classifier.out_features = len(full_train_dataset.classes)\n",
        "model.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Leak', 'Nonleaks']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataloader.dataset.dataset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, weight=None, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss() # extendable for multiclass classification as well\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # can try out lr scheduler later if needed\n",
        "    # can also try out warmup ratio\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        for batch_images, batch_labels in tqdm(train_dataloader):\n",
        "            batch_image_pixels, batch_labels = batch_images.pixel_values.squeeze(1).to(device), batch_labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_image_pixels).logits\n",
        "            loss = criterion(outputs, batch_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        accuracy = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_images, batch_labels in tqdm(val_dataloader, leave=False):\n",
        "                batch_image_pixels, batch_labels = batch_images.pixel_values.squeeze(1).to(device), batch_labels.to(device)\n",
        "                outputs = model(batch_image_pixels).logits\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                accuracy += (predicted == batch_labels).sum().item()\n",
        "                total_samples += batch_labels.size(0)\n",
        "\n",
        "        validation_accuracy = accuracy / total_samples\n",
        "        print(f\"Validation Accuracy: {validation_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adjust classweights to account for class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adjust Class weights here\n",
        "class_weight = {0: 8, 1: 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7acd8ffe0c7a4977bb0ba49841d60911",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6, Loss: 0.0043\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81595086992941c2a5273b1323028819",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9903\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3139933a625a4697b128f6587d6168d5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/6, Loss: 0.0111\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff906722668a41f6b759a9b40903f3f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9885\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f282c6c653d840ecbc9be27566e93f66",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/6, Loss: 0.0598\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e1209e9205349628b0f0ec416f86fd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9942\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbc51b9b55c44a72b18298c3b1c3d729",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/6, Loss: 0.0029\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ff265a63d36b429293dd9dfa3449b3aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9970\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d790521920641d29d54faa667be7ab7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/6, Loss: 0.0016\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da723a823bd94774b19b3de3d70769d2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9984\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abf21a958f72436289c17ad77b6b4686",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/6, Loss: 0.0005\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13b68f80e9de4b2b87ecc7f4146c163c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2174 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9990\n"
          ]
        }
      ],
      "source": [
        "train(model, class_weight, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the file path for saving the model\n",
        "model_path = 'vit_model_<insert_purpose>.pth'\n",
        "\n",
        "# Save the model's state_dict to the specified file\n",
        "torch.save(model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_path = 'vit_model_no_dropout.pth'\n",
        "model.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94kmsFvjVX7s"
      },
      "source": [
        "### Data Visualization (Confusion Matrix and ROC Curves)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "K2N5uezfVX7s"
      },
      "outputs": [],
      "source": [
        "class PerformanceVisualizationCallback(Callback):\n",
        "    def __init__(self, model, validation_data, num_batches, image_dir):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.validation_data = validation_data\n",
        "        self.num_batches = num_batches\n",
        "\n",
        "        os.makedirs(image_dir, exist_ok=True)\n",
        "        self.image_dir = image_dir\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        batch_num = 0\n",
        "        for data, true_label in self.validation_data:\n",
        "            batch_pred = self.model.predict(data, verbose=0)\n",
        "            y_pred.append(batch_pred)\n",
        "            y_true.append(true_label)\n",
        "\n",
        "            if batch_num >= self.num_batches:\n",
        "                break\n",
        "            batch_num += 1\n",
        "\n",
        "        y_true = np.concatenate(y_true, axis=0)\n",
        "        y_pred = np.concatenate(y_pred, axis=0)\n",
        "\n",
        "        threshold = 0.5\n",
        "        y_pred = (y_pred > threshold).astype(int)\n",
        "\n",
        "\n",
        "        # plot and save confusion matrix\n",
        "        fig, ax = plt.subplots(figsize=(16,12))\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        # cm_display = ConfusionMatrixDisplay(cm).plot(ax=ax, name=f\"Confusion Matrix of Validation Data at Epoch {epoch}\")\n",
        "        cm_display = ConfusionMatrixDisplay(cm).plot(ax=ax)\n",
        "        ax.set_title(f\"Confusion Matrix of Validation Data at Epoch {epoch}\")\n",
        "        fig.savefig(os.path.join(self.image_dir, f'confusion_matrix_epoch_{epoch}'))\n",
        "\n",
        "        # plot and save roc curve\n",
        "        fig, ax = plt.subplots(figsize=(16,12))\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
        "        # roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=ax, name=f\"ROC Curve of Validation Data at Epoch {epoch}\")\n",
        "        roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot(ax=ax)\n",
        "        ax.set_title(f\"ROC Curve of Validation Data at Epoch {epoch}\")\n",
        "        fig.savefig(os.path.join(self.image_dir, f'roc_curve_epoch_{epoch}'))\n",
        "\n",
        "performance_cbk = PerformanceVisualizationCallback(\n",
        "                      model=model,\n",
        "                      validation_data=val_generator,\n",
        "                      num_batches=len(val_generator),\n",
        "                      image_dir='performance_vizualizations')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jddooPmpVX7t"
      },
      "source": [
        "# Step 4: Evaluate the model on the Test Dataset\n",
        "\n",
        "### Generate evaluation metrics and plots such as confusion matrix and ROC curves, F1 score, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v4ikO-tVX7t"
      },
      "source": [
        "We are primarily concerned with high false positive rate due to the extreme class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(model):\n",
        "    model.eval()\n",
        "    accuracy = 0\n",
        "    total_samples = 0\n",
        "    predictions = []  # List to store the predictions\n",
        "    truth_labels = []  # List to store the truth labels\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_images, batch_labels in tqdm(test_dataloader, leave=False):\n",
        "            batch_image_pixels, batch_labels = batch_images.pixel_values.squeeze(1).to(device), batch_labels.to(device)\n",
        "            outputs = model(batch_image_pixels).logits\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            accuracy += (predicted == batch_labels).sum().item()\n",
        "            total_samples += batch_labels.size(0)\n",
        "\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "            truth_labels.extend(batch_labels.cpu().numpy())\n",
        "\n",
        "    validation_accuracy = accuracy / total_samples\n",
        "    print(f\"Test Accuracy: {validation_accuracy:.4f}\")\n",
        "    return predictions, truth_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7127d5a1f2d64caea53f8680b06497e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10869 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9990\n"
          ]
        }
      ],
      "source": [
        "predictions, truth_labels = predict(model)\n",
        "predictions, truth_labels = np.array(predictions), np.array(truth_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 750x750 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "#source: https://vitalflux.com/python-draw-confusion-matrix-matplotlib/\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true=truth_labels.astype(int), y_pred=predictions)\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title(f'Confusion Matrix (0: Leak, 1:Nonleak)', fontsize=18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "accuracy = accuracy_score(truth_labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.998950516116047"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9957514171642745"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1 = f1_score(truth_labels, predictions)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(truth_labels, predictions)\n",
        "per_class_accuracy = conf_matrix.diagonal() / conf_matrix.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'Nonleak' Accuracy: 0.9992\n",
            "Class 'Leak' Accuracy: 0.9975\n"
          ]
        }
      ],
      "source": [
        "for label, acc in zip(['Nonleak', 'Leak'], per_class_accuracy):\n",
        "    print(f\"Class '{label}' Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCvUK3ryVX7t"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "methane_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "92148a12c102ce31dad7b6dc4c1f8747c19091aa07dd8a934fcd2c33582f9a61"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
